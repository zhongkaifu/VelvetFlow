"""Structure planning logic for the planner."""

import copy
import json
import os
from typing import Any, Dict, List, Mapping, Optional

from openai import OpenAI

from velvetflow.config import OPENAI_MODEL
from velvetflow.logging_utils import (
    child_span,
    log_error,
    log_event,
    log_info,
    log_json,
    log_llm_usage,
    log_section,
    log_success,
    log_warn,
)
from velvetflow.planner.action_guard import ensure_registered_actions
from velvetflow.planner.approval import detect_missing_approval_nodes
from velvetflow.planner.coverage import check_requirement_coverage_with_llm
from velvetflow.planner.tools import PLANNER_TOOLS
from velvetflow.planner.workflow_builder import (
    WorkflowBuilder,
    attach_condition_branches,
)
from velvetflow.search import HybridActionSearchService
from velvetflow.models import infer_edges_from_bindings

LOOP_EXPORT_EDIT_TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "edit_loop_exports",
            "description": "ç¼–è¾‘ loop èŠ‚ç‚¹çš„ exportsï¼ˆitems/aggregatesï¼‰ï¼Œè¯·ç›´æ¥ç»™å‡ºå®Œæ•´çš„ exportsã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "exports": {
                        "type": "object",
                        "description": "å®Œæ•´çš„ exports å¯¹è±¡ï¼ŒåŒ…å« items/aggregatesã€‚",
                        "additionalProperties": True,
                    },
                    "items": {
                        "type": "object",
                        "description": "å¦‚æœä¸æä¾› exportsï¼Œä¹Ÿå¯ä»¥å•ç‹¬æä¾› items æ®µã€‚",
                        "properties": {
                            "from_node": {"type": "string"},
                            "fields": {
                                "type": "array",
                                "items": {"type": "string"},
                            },
                            "mode": {"type": "string", "enum": ["collect", "first", "last"]},
                        },
                    },
                    "aggregates": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "name": {"type": "string"},
                                "from_node": {"type": "string"},
                                "expr": {"type": "object", "additionalProperties": True},
                            },
                        },
                    },
                },
                "additionalProperties": False,
            },
        },
    }
]


def _attach_inferred_edges(workflow: Dict[str, Any]) -> Dict[str, Any]:
    """Rebuild derived edges so LLMs can see the implicit wiring."""

    copied = copy.deepcopy(workflow)
    nodes = copied.get("nodes") if isinstance(copied.get("nodes"), list) else []
    copied["edges"] = infer_edges_from_bindings(nodes)
    return attach_condition_branches(copied)


def _build_action_schema_map(action_registry: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:
    action_schemas: Dict[str, Dict[str, Any]] = {}
    for action in action_registry:
        aid = action.get("action_id")
        if not aid:
            continue
        action_schemas[aid] = {
            "name": action.get("name", ""),
            "description": action.get("description", ""),
            "domain": action.get("domain", ""),
            "arg_schema": action.get("arg_schema"),
            "output_schema": action.get("output_schema"),
        }
    return action_schemas


def _extract_loop_body_context(
    loop_node: Mapping[str, Any], action_schemas: Mapping[str, Mapping[str, Any]]
) -> Dict[str, Any]:
    params = loop_node.get("params") if isinstance(loop_node, Mapping) else None
    body = params.get("body_subgraph") if isinstance(params, Mapping) else None
    if not isinstance(body, Mapping):
        return {"nodes": []}

    context_nodes = []
    for child in body.get("nodes", []) or []:
        if not isinstance(child, Mapping):
            continue
        action_id = child.get("action_id")
        schema = action_schemas.get(action_id, {}) if isinstance(action_id, str) else {}
        context_nodes.append(
            {
                "id": child.get("id"),
                "type": child.get("type"),
                "action_id": action_id,
                "display_name": child.get("display_name"),
                "output_schema": schema.get("output_schema"),
            }
        )

    return {"nodes": context_nodes}


def _validate_loop_exports(
    *, loop_node: Mapping[str, Any], exports: Mapping[str, Any]
) -> List[str]:
    params = loop_node.get("params") if isinstance(loop_node.get("params"), Mapping) else {}
    body = params.get("body_subgraph") if isinstance(params, Mapping) else {}
    body_nodes = [bn for bn in body.get("nodes", []) or [] if isinstance(bn, Mapping)]
    body_ids = {bn.get("id") for bn in body_nodes if isinstance(bn.get("id"), str)}

    errors: List[str] = []

    if not isinstance(exports, Mapping):
        return ["exports å¿…é¡»æ˜¯å¯¹è±¡"]

    items = exports.get("items")
    if not isinstance(items, Mapping):
        errors.append("ç¼ºå°‘ items å¯¹è±¡")
    else:
        from_node = items.get("from_node")
        if not isinstance(from_node, str) or from_node not in body_ids:
            errors.append("items.from_node å¿…é¡»å¼•ç”¨ body_subgraph.nodes ä¸­çš„èŠ‚ç‚¹")

        fields = items.get("fields")
        if not (isinstance(fields, list) and [f for f in fields if isinstance(f, str)]):
            errors.append("items.fields å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²æ•°ç»„")

        mode = items.get("mode")
        if mode is not None and mode not in {"collect", "first", "last"}:
            errors.append("items.mode ä»…æ”¯æŒ collect/first/last")

    aggregates = exports.get("aggregates")
    if aggregates is not None:
        if not isinstance(aggregates, list):
            errors.append("aggregates å¿…é¡»æ˜¯æ•°ç»„æˆ–çœç•¥")
        else:
            for idx, agg in enumerate(aggregates):
                if not isinstance(agg, Mapping):
                    errors.append(f"aggregates[{idx}] å¿…é¡»æ˜¯å¯¹è±¡")
                    continue

                if not isinstance(agg.get("name"), str):
                    errors.append(f"aggregates[{idx}].name å¿…é¡»æ˜¯å­—ç¬¦ä¸²")

                from_node = agg.get("from_node")
                if not isinstance(from_node, str) or from_node not in body_ids:
                    errors.append(
                        f"aggregates[{idx}].from_node å¿…é¡»å¼•ç”¨ body_subgraph.nodes ä¸­çš„èŠ‚ç‚¹"
                    )

                expr = agg.get("expr")
                if not isinstance(expr, Mapping):
                    errors.append(f"aggregates[{idx}].expr å¿…é¡»æ˜¯å¯¹è±¡")

    return errors


def _fallback_loop_exports(
    loop_node: Mapping[str, Any], action_schemas: Mapping[str, Mapping[str, Any]]
) -> Optional[Dict[str, Any]]:
    params = loop_node.get("params") if isinstance(loop_node, Mapping) else None
    if not isinstance(params, Mapping):
        return None
    body = params.get("body_subgraph")
    if not isinstance(body, Mapping):
        return None

    body_nodes = [bn for bn in body.get("nodes", []) or [] if isinstance(bn, Mapping)]
    body_ids = [bn.get("id") for bn in body_nodes if isinstance(bn.get("id"), str)]
    exit_node = body.get("exit") if isinstance(body.get("exit"), str) else None
    from_node = exit_node if exit_node in body_ids else (body_ids[0] if body_ids else None)
    if not from_node:
        return None

    field_candidates: List[str] = []
    target_node = next((bn for bn in body_nodes if bn.get("id") == from_node), None)
    if isinstance(target_node, Mapping):
        action_id = target_node.get("action_id")
        schema = action_schemas.get(action_id, {}) if isinstance(action_id, str) else {}
        props = schema.get("output_schema", {}).get("properties") if isinstance(schema.get("output_schema"), Mapping) else None
        if isinstance(props, Mapping):
            field_candidates = [k for k in props.keys() if isinstance(k, str)]

    fields = field_candidates[:4] if field_candidates else ["status"]
    return {
        "items": {
            "from_node": from_node,
            "fields": fields,
            "mode": "collect",
        },
        "aggregates": [],
    }


def _ensure_loop_items_fields(
    *,
    exports: Mapping[str, Any],
    loop_node: Mapping[str, Any],
    action_schemas: Mapping[str, Mapping[str, Any]],
) -> Dict[str, Any]:
    """Ensure items.fields is a non-empty list.

    If the original exports already contains non-empty fields, it will be
    returned unchanged. Otherwise, we try to infer several representative
    fields from the referenced body node's output schema; fall back to a
    single "status" field if nothing is available.
    """

    items_spec = exports.get("items")
    if not isinstance(items_spec, Mapping):
        return dict(exports)

    fields = items_spec.get("fields") if isinstance(items_spec.get("fields"), list) else []
    normalized_fields = [f for f in fields if isinstance(f, str)]
    if normalized_fields:
        return exports

    params = loop_node.get("params") if isinstance(loop_node.get("params"), Mapping) else {}
    body = params.get("body_subgraph") if isinstance(params, Mapping) else {}
    body_nodes = [bn for bn in body.get("nodes", []) or [] if isinstance(bn, Mapping)]
    target_id = items_spec.get("from_node") if isinstance(items_spec.get("from_node"), str) else None
    target_node = next((bn for bn in body_nodes if bn.get("id") == target_id), None)

    fallback_fields: list[str] = []
    if isinstance(target_node, Mapping):
        action_id = target_node.get("action_id") if isinstance(target_node.get("action_id"), str) else None
        schema = action_schemas.get(action_id, {}) if isinstance(action_id, str) else {}
        props = schema.get("output_schema", {}).get("properties") if isinstance(schema.get("output_schema"), Mapping) else None
        if isinstance(props, Mapping):
            fallback_fields = [k for k in props.keys() if isinstance(k, str)]

    if not fallback_fields:
        fallback_fields = ["status"]

    new_items = dict(items_spec)
    new_items["fields"] = fallback_fields[:4]
    new_exports = dict(exports)
    new_exports["items"] = new_items
    return new_exports


def _synthesize_loop_exports_with_llm(
    *,
    client: OpenAI,
    model: str,
    nl_requirement: str,
    loop_node: Mapping[str, Any],
    action_schemas: Mapping[str, Mapping[str, Any]],
) -> Optional[Dict[str, Any]]:
    body_context = _extract_loop_body_context(loop_node, action_schemas)
    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºå¾ªç¯èŠ‚ç‚¹è®¾è®¡ exports çš„åŠ©æ‰‹ã€‚\n"
        "ç»™å®š loop èŠ‚ç‚¹ï¼ˆå« body_subgraphï¼‰ä»¥åŠä¸Šæ¸¸çš„è‡ªç„¶è¯­è¨€éœ€æ±‚ï¼Œ"
        "è¯·è¾“å‡ºç¬¦åˆ DSL çš„ exports ç»“æ„ï¼Œç”¨äºå°†å¾ªç¯å­å›¾çš„ç»“æœæš´éœ²ç»™å¤–éƒ¨èŠ‚ç‚¹ã€‚\n"
        "è¦æ±‚ï¼š\n"
        "1) åªè¾“å‡º JSONï¼ˆä¸è¦ä»£ç å—ï¼‰ï¼Œæ ¼å¼å¯ä»¥æ˜¯ {\"exports\": {...}} æˆ–ç›´æ¥ exports å¯¹è±¡ã€‚\n"
        "2) items.from_node å¿…é¡»å¼•ç”¨ body_subgraph.nodes ä¸­çš„èŠ‚ç‚¹ï¼Œfields éœ€åˆ—å‡ºä½ å¸Œæœ›æš´éœ²çš„å­—æ®µã€‚\n"
        "3) aggregates æ˜¯å¯é€‰çš„ count_if/max/min/sum/avg èšåˆï¼Œfrom_node åŒæ ·åªèƒ½æŒ‡å‘ body_subgraph èŠ‚ç‚¹ã€‚\n"
        "4) é¿å…è‡ªç„¶è¯­è¨€è§£é‡Šï¼Œä½¿ç”¨ç»“æ„åŒ–è¡¨è¾¾å¼ï¼Œå­—æ®µåä¼˜å…ˆä¾æ®èŠ‚ç‚¹ output_schema.propertiesã€‚\n"
        "ç¤ºä¾‹ï¼ˆä»…ç¤ºæ„ï¼Œä¸è¦ç”Ÿæ¬ç¡¬å¥—å­—æ®µåï¼‰ï¼š\n"
        "{\n  \"items\": {\"from_node\": \"finish_employee\", \"fields\": [\"employee_id\", \"risk\"], \"mode\": \"collect\"},\n"
        " \"aggregates\": [{\"name\": \"high_risk_count\", \"from_node\": \"finish_employee\", \"expr\": {\"kind\": \"count_if\", \"field\": \"risk\", \"op\": \">\", \"value\": 0.8}}]\n}"
    )

    payload = {
        "nl_requirement": nl_requirement,
        "loop_node": loop_node,
        "loop_body": body_context,
        "hint": "é€‰æ‹©å…·æœ‰å®Œæ•´è¾“å‡ºçš„èŠ‚ç‚¹ä½œä¸º items.from_nodeï¼Œå­—æ®µæ¥è‡ªå…¶ output_schema.propertiesã€‚",
    }

    with child_span("loop_exports_llm"):
        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": json.dumps(payload, ensure_ascii=False)},
            ],
            temperature=0.2,
        )
    log_llm_usage(model, getattr(resp, "usage", None), operation="synthesize_loop_exports")
    if not resp.choices:
        raise RuntimeError("_synthesize_loop_exports_with_llm æœªè¿”å›ä»»ä½•å€™é€‰æ¶ˆæ¯")

    content = resp.choices[0].message.content or ""
    text = content.strip()
    if text.startswith("```"):
        text = text.strip("`")
        if "\n" in text:
            first_line, rest = text.split("\n", 1)
            if first_line.strip().lower().startswith("json"):
                text = rest

    decoder = json.JSONDecoder()
    parsed: Any
    try:
        parsed, _ = decoder.raw_decode(text)
    except json.JSONDecodeError:
        return None

    if isinstance(parsed, Mapping):
        exports = parsed.get("exports") if "exports" in parsed else parsed
        if isinstance(exports, Mapping):
            return dict(exports)
    return None


def _extract_exports_from_tool_args(raw_args: Any) -> Optional[Dict[str, Any]]:
    if not isinstance(raw_args, Mapping):
        return None

    if isinstance(raw_args.get("exports"), Mapping):
        return dict(raw_args["exports"])

    candidate: Dict[str, Any] = {}
    if isinstance(raw_args.get("items"), Mapping):
        candidate["items"] = raw_args["items"]
    if isinstance(raw_args.get("aggregates"), list):
        candidate["aggregates"] = raw_args["aggregates"]

    return candidate or None


def _plan_loop_exports_with_tools(
    *,
    client: OpenAI,
    model: str,
    nl_requirement: str,
    loop_node: Mapping[str, Any],
    action_schemas: Mapping[str, Mapping[str, Any]],
) -> Optional[Dict[str, Any]]:
    body_context = _extract_loop_body_context(loop_node, action_schemas)
    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºå¾ªç¯èŠ‚ç‚¹è®¾è®¡ exports çš„åŠ©æ‰‹ã€‚\n"
        "ä½ å¯ä»¥è°ƒç”¨å·¥å…· edit_loop_exports ç›´æ¥ç»™å‡º exports å¯¹è±¡ã€‚\n"
        "è¦æ±‚ï¼šitems.from_node å¿…é¡»å¼•ç”¨ body_subgraph.nodes ä¸­çš„èŠ‚ç‚¹ï¼ˆé¦–é€‰ exitï¼‰ï¼Œfields éœ€åˆ—å‡ºä½ å¸Œæœ›æš´éœ²çš„å­—æ®µã€‚"
    )

    payload = {
        "nl_requirement": nl_requirement,
        "loop_node": loop_node,
        "loop_body": body_context,
        "hint": "ä½¿ç”¨å·¥å…·è¾“å‡ºå®Œæ•´ exportsï¼Œå¯¹ aggregates å¯é€‰å¡« count_if/sum/avg ç­‰è¡¨è¾¾å¼ã€‚",
    }

    messages: List[Dict[str, Any]] = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": json.dumps(payload, ensure_ascii=False)},
    ]

    for round_idx in range(3):
        with child_span(f"loop_exports_tool_round_{round_idx}"):
            resp = client.chat.completions.create(
                model=model,
                messages=messages,
                tools=LOOP_EXPORT_EDIT_TOOLS,
                tool_choice="auto",
                temperature=0.2,
            )
        log_llm_usage(model, getattr(resp, "usage", None), operation="plan_loop_exports")
        if not resp.choices:
            raise RuntimeError("_plan_loop_exports_with_tools æœªè¿”å›ä»»ä½•å€™é€‰æ¶ˆæ¯")

        msg = resp.choices[0].message
        messages.append({
            "role": "assistant",
            "content": msg.content or "",
            "tool_calls": msg.tool_calls,
        })

        if msg.tool_calls:
            for tc in msg.tool_calls:
                tool_call_id = tc.id
                func_name = tc.function.name
                raw_args = tc.function.arguments
                try:
                    args = json.loads(raw_args) if raw_args else {}
                except json.JSONDecodeError:
                    log_error(f"[Error] è§£æ exports å·¥å…·å‚æ•°å¤±è´¥: {raw_args}")
                    args = {}

                if func_name != "edit_loop_exports":
                    tool_result = {"status": "error", "message": f"æœªçŸ¥å·¥å…· {func_name}"}
                else:
                    extracted = _extract_exports_from_tool_args(args)
                    if extracted:
                        validation_errors = _validate_loop_exports(
                            loop_node=loop_node, exports=extracted
                        )
                        if not validation_errors:
                            tool_result = {
                                "status": "ok",
                                "message": "å·²æ¥æ”¶å¹¶é€šè¿‡æ ¡éªŒçš„ exports",
                                "exports": extracted,
                            }
                            messages.append(
                                {
                                    "role": "tool",
                                    "tool_call_id": tool_call_id,
                                    "content": json.dumps(tool_result, ensure_ascii=False),
                                }
                            )
                            return extracted

                        tool_result = {
                            "status": "error",
                            "message": "exports æ ¡éªŒå¤±è´¥ï¼Œè¯·ä¿®æ­£åé‡è¯•",
                            "errors": validation_errors,
                        }
                    else:
                        tool_result = {"status": "error", "message": "æœªæä¾›åˆæ³•çš„ exports"}

                messages.append(
                    {
                        "role": "tool",
                        "tool_call_id": tool_call_id,
                        "content": json.dumps(tool_result, ensure_ascii=False),
                    }
                )

            continue

        text = (msg.content or "").strip()
        if not text:
            continue
        decoder = json.JSONDecoder()
        try:
            parsed, _ = decoder.raw_decode(text)
        except json.JSONDecodeError:
            log_warn("[Planner] LLM æ²¡æœ‰è°ƒç”¨å·¥å…·ä¸”è¿”å›å†…å®¹æ— æ³•è§£æä¸º JSONã€‚")
            continue

        if isinstance(parsed, Mapping):
            exports = parsed.get("exports") if "exports" in parsed else parsed
            if isinstance(exports, Mapping):
                validation_errors = _validate_loop_exports(
                    loop_node=loop_node, exports=exports
                )
                if not validation_errors:
                    return dict(exports)
                log_warn(
                    "[Planner] LLM æ–‡æœ¬è¿”å›çš„ exports æœªé€šè¿‡æ ¡éªŒï¼Œå°†ç»§ç»­å°è¯•ã€‚"
                )

    return None


def _ensure_loop_exports_with_llm(
    *,
    workflow: Dict[str, Any],
    action_registry: List[Dict[str, Any]],
    nl_requirement: str,
    model: str,
) -> Dict[str, Any]:
    nodes = workflow.get("nodes", []) if isinstance(workflow, Mapping) else []
    loop_nodes = [n for n in nodes if isinstance(n, Mapping) and n.get("type") == "loop"]
    if not loop_nodes:
        return workflow

    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
    action_schemas = _build_action_schema_map(action_registry)

    new_nodes: List[Dict[str, Any]] = []
    for node in nodes:
        if not isinstance(node, Mapping) or node.get("type") != "loop":
            new_nodes.append(node)
            continue

        params = node.get("params") if isinstance(node.get("params"), Mapping) else {}
        exports = params.get("exports") if isinstance(params, Mapping) else None
        if isinstance(exports, Mapping) and exports:
            ensured_exports = _ensure_loop_items_fields(
                exports=exports, loop_node=node, action_schemas=action_schemas
            )
            new_params = dict(params)
            new_params["exports"] = ensured_exports
            new_node = dict(node)
            new_node["params"] = new_params
            new_nodes.append(new_node)
            continue

        synthesized: Optional[Dict[str, Any]] = None
        planned = _plan_loop_exports_with_tools(
            client=client,
            model=model,
            nl_requirement=nl_requirement,
            loop_node=node,
            action_schemas=action_schemas,
        )
        used_tool = planned is not None
        if not planned:
            synthesized = _synthesize_loop_exports_with_llm(
                client=client,
                model=model,
                nl_requirement=nl_requirement,
                loop_node=node,
                action_schemas=action_schemas,
            )
            planned = synthesized

        if not planned:
            planned = _fallback_loop_exports(node, action_schemas) or {}
            log_warn(
                f"[Planner] LLM æœªèƒ½ç”Ÿæˆ exportsï¼Œloop èŠ‚ç‚¹ {node.get('id')} ä½¿ç”¨å…œåº• exportsã€‚"
            )
        elif used_tool:
            log_info(f"[Planner] LLM å·¥å…·å·²ä¸º loop èŠ‚ç‚¹ {node.get('id')} ç¼–è¾‘ exportsã€‚")
        elif synthesized is planned:
            log_info(f"[Planner] LLM å·²ä¸º loop èŠ‚ç‚¹ {node.get('id')} ç”Ÿæˆ exportsã€‚")

        ensured_exports = _ensure_loop_items_fields(
            exports=planned, loop_node=node, action_schemas=action_schemas
        )
        new_params = dict(params)
        new_params["exports"] = ensured_exports
        new_node = dict(node)
        new_node["params"] = new_params
        new_nodes.append(new_node)

    new_workflow = dict(workflow)
    new_workflow["nodes"] = new_nodes
    return new_workflow


def _prepare_skeleton_for_coverage(
    *,
    builder: WorkflowBuilder,
    action_registry: List[Dict[str, Any]],
    search_service: HybridActionSearchService,
) -> Dict[str, Any]:
    skeleton = _attach_inferred_edges(builder.to_workflow())
    skeleton = ensure_registered_actions(
        skeleton, action_registry=action_registry, search_service=search_service
    )
    return _attach_inferred_edges(skeleton)


def _run_coverage_check(
    *,
    nl_requirement: str,
    builder: WorkflowBuilder,
    action_registry: List[Dict[str, Any]],
    search_service: HybridActionSearchService,
) -> Dict[str, Any]:
    skeleton = _prepare_skeleton_for_coverage(
        builder=builder, action_registry=action_registry, search_service=search_service
    )

    coverage = check_requirement_coverage_with_llm(
        nl_requirement=nl_requirement,
        workflow=skeleton,
        model=OPENAI_MODEL,
    )
    approval_missing = detect_missing_approval_nodes(
        workflow=skeleton, action_registry=action_registry
    )
    if approval_missing:
        coverage.setdefault("missing_points", [])
        coverage["missing_points"].extend(approval_missing)
        coverage["is_covered"] = False

    log_event("coverage_check", {"coverage": coverage})
    log_json("è¦†ç›–åº¦æ£€æŸ¥ç»“æœ", coverage)
    return skeleton, coverage


def _build_coverage_feedback_message(
    *, coverage: Mapping[str, Any], workflow: Mapping[str, Any]
) -> str:
    missing_points = coverage.get("missing_points", []) or []
    analysis = coverage.get("analysis", "")
    return (
        "è¦†ç›–åº¦æ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·ç»§ç»­ä½¿ç”¨è§„åˆ’å·¥å…·è¡¥å……ç¼ºå¤±ç‚¹ï¼Œå¹¶å†æ¬¡è°ƒç”¨ finalize_workflowã€‚\n"
        f"- missing_points: {json.dumps(missing_points, ensure_ascii=False)}\n"
        f"- analysis: {analysis}\n"
        "å½“å‰ workflow ä¾›å‚è€ƒï¼ˆå«æ¨å¯¼çš„ edgesï¼‰ï¼š\n"
        f"{json.dumps(workflow, ensure_ascii=False)}"
    )


def plan_workflow_structure_with_llm(
    nl_requirement: str,
    search_service: HybridActionSearchService,
    action_registry: List[Dict[str, Any]],
    max_rounds: int = 10,
    max_coverage_refine_rounds: int = 2,
) -> Dict[str, Any]:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
    builder = WorkflowBuilder()
    last_action_candidates: List[str] = []

    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªé€šç”¨ä¸šåŠ¡å·¥ä½œæµç¼–æ’åŠ©æ‰‹ã€‚\n"
        "ç³»ç»Ÿä¸­æœ‰ä¸€ä¸ª Action Registryï¼ŒåŒ…å«å¤§é‡ä¸šåŠ¡åŠ¨ä½œï¼Œä½ åªèƒ½é€šè¿‡ search_business_actions æŸ¥è¯¢ã€‚\n"
        "æ„å»ºæ–¹å¼ï¼š\n"
        "1) ä½¿ç”¨ set_workflow_meta è®¾ç½®å·¥ä½œæµåç§°å’Œæè¿°ã€‚\n"
        "2) å½“éœ€è¦ä¸šåŠ¡åŠ¨ä½œæ—¶ï¼Œå¿…é¡»å…ˆç”¨ search_business_actions æŸ¥è¯¢å€™é€‰ï¼›add_node(type='action') çš„ action_id å¿…é¡»å–è‡ªæœ€è¿‘ä¸€æ¬¡ candidates.idã€‚\n"
        "3) å¦‚éœ€ä¿®æ”¹å·²åˆ›å»ºèŠ‚ç‚¹ï¼ˆè¡¥å…… display_name/params/åˆ†æ”¯æŒ‡å‘ç­‰ï¼‰ï¼Œè¯·è°ƒç”¨ update_node å¹¶ä¼ å…¥éœ€è¦è¦†ç›–çš„å­—æ®µåˆ—è¡¨ã€‚\n"
        "4) condition èŠ‚ç‚¹å¿…é¡»æ˜¾å¼æä¾› true_to_node å’Œ false_to_nodeï¼Œå€¼å¯ä»¥æ˜¯èŠ‚ç‚¹ idï¼ˆç»§ç»­æ‰§è¡Œï¼‰æˆ– nullï¼ˆè¡¨ç¤ºè¯¥åˆ†æ”¯ç»“æŸï¼‰ï¼›é€šè¿‡èŠ‚ç‚¹ params ä¸­çš„è¾“å…¥/è¾“å‡ºå¼•ç”¨è¡¨è¾¾ä¾èµ–å…³ç³»ï¼Œä¸éœ€è¦æ˜¾å¼ç»˜åˆ¶ edgesã€‚\n"
        "5) å½“ç»“æ„å®Œæˆæ—¶è°ƒç”¨ finalize_workflowã€‚\n\n"
        "ã€éå¸¸é‡è¦çš„åŸåˆ™ã€‘\n"
        "1. æ‰€æœ‰ç¤ºä¾‹ï¼ˆåŒ…æ‹¬åç»­ä½ åœ¨è¡¥å‚é˜¶æ®µçœ‹åˆ°çš„ç¤ºä¾‹ï¼‰éƒ½åªæ˜¯ä¸ºè¯´æ˜â€œDSL çš„å†™æ³•â€å’Œâ€œèŠ‚ç‚¹ä¹‹é—´å¦‚ä½•è¿çº¿â€ï¼Œ\n"
        "   ä¸æ˜¯å®é™…çš„ä¸šåŠ¡çº¦æŸï¼Œä¸è¦åœ¨æ–°ä»»åŠ¡é‡Œç¡¬å¤ç”¨è¿™äº›ç¤ºä¾‹ä¸­çš„ä¸šåŠ¡åæˆ–å­—æ®µåã€‚\n"
        "2. ä½ å¿…é¡»ä¸¥æ ¼å›´ç»•å½“å‰å¯¹è¯ä¸­çš„è‡ªç„¶è¯­è¨€éœ€æ±‚æ¥è®¾è®¡ workflowï¼š\n"
        "   - è§¦å‘æ–¹å¼ï¼ˆå®šæ—¶ / äº‹ä»¶ / æ‰‹åŠ¨ï¼‰\n"
        "   - æ•°æ®æŸ¥è¯¢/è¯»å–\n"
        "   - ç­›é€‰/è¿‡æ»¤æ¡ä»¶\n"
        "   - èšåˆ/ç»Ÿè®¡/æ€»ç»“\n"
        "   - é€šçŸ¥ / å†™å…¥ / è½åº“ / è°ƒç”¨ä¸‹æ¸¸ç³»ç»Ÿ\n"
        "3. ä¸å…è®¸ä¸ºäº†æ¨¡ä»¿ç¤ºä¾‹ï¼Œè€Œåœ¨ä¸å½“å‰ä»»åŠ¡æ— å…³çš„æƒ…å†µä¸‹å¼•å…¥â€œå¥åº·/ä½“æ¸©/æ–°é—»/Nvidia/å‘˜å·¥/HRâ€ç­‰å…·ä½“è¯æ±‡ã€‚\n\n"
        "4. å¾ªç¯èŠ‚ç‚¹çš„å†…éƒ¨æ•°æ®åªèƒ½é€šè¿‡ loop.exports æš´éœ²ç»™å¤–éƒ¨ï¼Œä¸‹æ¸¸å¼•ç”¨å¾ªç¯ç»“æœæ—¶å¿…é¡»ä½¿ç”¨ result_of.<loop_id>.itemsï¼ˆæˆ– result_of.<loop_id>.exports.itemsï¼‰/ result_of.<loop_id>.aggregates.*ï¼Œç¦æ­¢ç›´æ¥å¼•ç”¨ body å­å›¾çš„èŠ‚ç‚¹ã€‚\n\n"
        "ã€è¦†ç›–åº¦è¦æ±‚ã€‘\n"
        "ä½ å¿…é¡»ç¡®ä¿å·¥ä½œæµç»“æ„èƒ½å¤Ÿå®Œå…¨è¦†ç›–ç”¨æˆ·è‡ªç„¶è¯­è¨€éœ€æ±‚ä¸­çš„æ¯ä¸ªå­ä»»åŠ¡ï¼Œè€Œä¸æ˜¯åªè¦†ç›–å‰åŠéƒ¨åˆ†ï¼š\n"
        "ä¾‹å¦‚ï¼Œå¦‚æœéœ€æ±‚åŒ…å«ï¼šè§¦å‘ + æŸ¥è¯¢ + ç­›é€‰ + æ€»ç»“ + é€šçŸ¥ï¼Œä½ ä¸èƒ½åªå®ç°è§¦å‘ + æŸ¥è¯¢ï¼Œ\n"
        "å¿…é¡»åœ¨ç»“æ„é‡Œæ˜¾å¼åŒ…å«ç­›é€‰ã€æ€»ç»“ã€é€šçŸ¥ç­‰å¯¹åº”èŠ‚ç‚¹å’Œæ•°æ®æµã€‚\n"
        "è°ƒç”¨ finalize_workflow åç³»ç»Ÿä¼šç«‹å³å¯¹ç…§ nl_requirement åšè¦†ç›–åº¦æ£€æŸ¥ï¼›å¦‚æœå‘ç° missing_points ä¼šæŠŠç¼ºå¤±ç‚¹å’Œå½“å‰ workflow åé¦ˆç»™ä½ ï¼Œè¯·ç»§ç»­ç”¨è§„åˆ’å·¥å…·ä¿®è¡¥åå†æ¬¡ finalizeã€‚"
    )

    messages: List[Dict[str, Any]] = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": nl_requirement},
    ]

    finalized = False
    latest_skeleton: Dict[str, Any] = {}
    latest_coverage: Dict[str, Any] = {}
    coverage_retry = 0
    total_rounds = max_rounds + max_coverage_refine_rounds

    # ---------- ç»“æ„è§„åˆ’ï¼ˆå¤šè½® tool-callingï¼‰ ----------
    for round_idx in range(total_rounds):
        log_section(f"ç»“æ„è§„åˆ’ Round {round_idx + 1}")
        with child_span("structure_planning_llm"):
            resp = client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=messages,
                tools=PLANNER_TOOLS,
                tool_choice="auto",
                temperature=0.2,
            )
        log_llm_usage(OPENAI_MODEL, getattr(resp, "usage", None), operation="structure_planning")
        if not resp.choices:
            raise RuntimeError("plan_workflow_structure_with_llm æœªè¿”å›ä»»ä½•å€™é€‰æ¶ˆæ¯")

        msg = resp.choices[0].message
        messages.append(
            {
                "role": "assistant",
                "content": msg.content or "",
                "tool_calls": msg.tool_calls,
            }
        )

        if not msg.tool_calls:
            log_warn("[Planner] æœ¬è½®æ²¡æœ‰ tool_callsï¼Œæå‰ç»“æŸã€‚")
            break

        for tc in msg.tool_calls:
            func_name = tc.function.name
            raw_args = tc.function.arguments
            tool_call_id = tc.id
            try:
                args = json.loads(raw_args) if raw_args else {}
            except json.JSONDecodeError:
                log_error(f"[Error] è§£æå·¥å…·å‚æ•°å¤±è´¥: {raw_args}")
                args = {}

            log_info(f"[Planner] è°ƒç”¨å·¥å…·: {func_name}({args})")

            if func_name == "search_business_actions":
                query = args.get("query", "")
                top_k = int(args.get("top_k", 5))
                actions_raw = search_service.search(query=query, top_k=top_k)
                candidates = [
                    {
                        "id": a.get("action_id"),
                        "name": a.get("name", ""),
                        "description": a.get("description", ""),
                        "category": a.get("domain") or "general",
                    }
                    for a in actions_raw
                    if a.get("action_id")
                ]
                last_action_candidates = [c["id"] for c in candidates]
                tool_result = {
                    "status": "ok",
                    "query": query,
                    "actions": actions_raw,
                    "candidates": candidates,
                }

            elif func_name == "set_workflow_meta":
                builder.set_meta(args.get("workflow_name", ""), args.get("description"))
                tool_result = {"status": "ok", "type": "meta_set"}

            elif func_name == "add_node":
                node_type = args["type"]
                action_id = args.get("action_id")
                true_to_node = args.get("true_to_node")
                false_to_node = args.get("false_to_node")

                if node_type == "condition":
                    missing_fields = [
                        name
                        for name in ("true_to_node", "false_to_node")
                        if name not in args
                    ]
                    non_str_fields = [
                        name
                        for name, value in (
                            ("true_to_node", true_to_node),
                            ("false_to_node", false_to_node),
                        )
                        if value is not None and not isinstance(value, str)
                    ]

                    if missing_fields or non_str_fields:
                        tool_result = {
                            "status": "error",
                            "message": (
                                "condition èŠ‚ç‚¹éœ€è¦æä¾› true_to_node/false_to_node å­—æ®µï¼Œå€¼å¯ä¸ºèŠ‚ç‚¹ idï¼ˆç»§ç»­æ‰§è¡Œï¼‰"
                                "æˆ– nullï¼ˆè¡¨ç¤ºè¯¥åˆ†æ”¯ç»“æŸï¼‰ï¼Œéå­—ç¬¦ä¸²/æœªæä¾›ä¼šè¢«æ‹’ç»ã€‚"
                            ),
                            "missing_fields": missing_fields,
                            "invalid_fields": non_str_fields,
                        }
                        messages.append(
                            {
                                "role": "tool",
                                "tool_call_id": tool_call_id,
                                "content": json.dumps(tool_result, ensure_ascii=False),
                            }
                        )
                        continue

                if node_type == "action":
                    if not last_action_candidates:
                        tool_result = {
                            "status": "error",
                            "message": "action èŠ‚ç‚¹å¿…é¡»åœ¨è°ƒç”¨ search_business_actions ä¹‹ååˆ›å»ºï¼Œè¯·å…ˆæŸ¥è¯¢å€™é€‰åŠ¨ä½œã€‚",
                        }
                    elif action_id not in last_action_candidates:
                        tool_result = {
                            "status": "error",
                            "message": "action_id å¿…é¡»æ˜¯æœ€è¿‘ä¸€æ¬¡ search_business_actions è¿”å›çš„ candidates.id ä¹‹ä¸€ã€‚",
                            "allowed_action_ids": last_action_candidates,
                        }
                    else:
                        builder.add_node(
                            node_id=args["id"],
                            node_type=node_type,
                            action_id=action_id,
                            display_name=args.get("display_name"),
                            params=args.get("params") or {},
                            true_to_node=true_to_node if isinstance(true_to_node, str) else None,
                            false_to_node=false_to_node if isinstance(false_to_node, str) else None,
                        )
                        tool_result = {"status": "ok", "type": "node_added", "node_id": args["id"]}
                else:
                    builder.add_node(
                        node_id=args["id"],
                        node_type=node_type,
                        action_id=action_id,
                        display_name=args.get("display_name"),
                        params=args.get("params") or {},
                        true_to_node=true_to_node if isinstance(true_to_node, str) else None,
                        false_to_node=false_to_node if isinstance(false_to_node, str) else None,
                    )
                    tool_result = {"status": "ok", "type": "node_added", "node_id": args["id"]}

            elif func_name == "update_node":
                node_id = args.get("id")
                updates = args.get("updates")

                if not isinstance(node_id, str):
                    tool_result = {"status": "error", "message": "update_node éœ€è¦æä¾›å­—ç¬¦ä¸²ç±»å‹çš„ idã€‚"}
                elif node_id not in builder.nodes:
                    tool_result = {"status": "error", "message": f"èŠ‚ç‚¹ {node_id} å°šæœªåˆ›å»ºï¼Œæ— æ³•æ›´æ–°ã€‚"}
                elif not isinstance(updates, list):
                    tool_result = {
                        "status": "error",
                        "message": "updates å¿…é¡»æ˜¯ {op,key,value} å¯¹è±¡ç»„æˆçš„æ•°ç»„ã€‚",
                    }
                else:
                    invalid_entries = []
                    invalid_branch_fields = []
                    invalid_ops = []
                    normalized_updates = []
                    for idx, entry in enumerate(updates):
                        if not isinstance(entry, Mapping):
                            invalid_entries.append(idx)
                            continue

                        op = entry.get("op", "modify")
                        if op not in {"add", "modify", "remove"}:
                            invalid_ops.append(idx)
                            continue

                        key = entry.get("key")
                        if not isinstance(key, str):
                            invalid_entries.append(idx)
                            continue

                        value = entry.get("value") if "value" in entry else None
                        if (
                            op != "remove"
                            and key in {"true_to_node", "false_to_node"}
                            and value is not None
                            and not isinstance(value, str)
                        ):
                            invalid_branch_fields.append(key)
                            continue

                        normalized_updates.append({"op": op, "key": key, "value": value})

                    node_type = builder.nodes.get(node_id, {}).get("type")
                    if invalid_entries:
                        tool_result = {
                            "status": "error",
                            "message": f"updates[{invalid_entries}] ä¸æ˜¯åˆæ³•çš„ {{op,key,value}} å¯¹è±¡ã€‚",
                        }
                    elif invalid_ops:
                        tool_result = {
                            "status": "error",
                            "message": f"updates[{invalid_ops}] åŒ…å«ä¸æ”¯æŒçš„ opï¼ˆä»…æ”¯æŒ add/modify/removeï¼‰ã€‚",
                        }
                    elif invalid_branch_fields:
                        tool_result = {
                            "status": "error",
                            "message": "condition çš„ true_to_node/false_to_node åªèƒ½æ˜¯èŠ‚ç‚¹ id æˆ– nullã€‚",
                            "invalid_fields": invalid_branch_fields,
                        }
                    elif node_type == "action" and any(
                        entry.get("op", "modify") != "remove" and entry.get("key") == "action_id"
                        for entry in normalized_updates
                    ):
                        new_action_id = next(
                            entry.get("value")
                            for entry in normalized_updates
                            if entry.get("op", "modify") != "remove" and entry.get("key") == "action_id"
                        )
                        if not last_action_candidates:
                            tool_result = {
                                "status": "error",
                                "message": "æ›´æ–° action_id å‰è¯·å…ˆè°ƒç”¨ search_business_actions ä»¥è·å–å€™é€‰ã€‚",
                            }
                        elif new_action_id not in last_action_candidates:
                            tool_result = {
                                "status": "error",
                                "message": "action_id å¿…é¡»æ˜¯æœ€è¿‘ä¸€æ¬¡ search_business_actions è¿”å›çš„ candidates.id ä¹‹ä¸€ã€‚",
                                "allowed_action_ids": last_action_candidates,
                            }
                        else:
                            builder.update_node(node_id, normalized_updates)
                            tool_result = {"status": "ok", "type": "node_updated", "node_id": node_id}
                    else:
                        builder.update_node(node_id, normalized_updates)
                        tool_result = {"status": "ok", "type": "node_updated", "node_id": node_id}

            elif func_name == "finalize_workflow":
                skeleton, coverage = _run_coverage_check(
                    nl_requirement=nl_requirement,
                    builder=builder,
                    action_registry=action_registry,
                    search_service=search_service,
                )
                latest_skeleton = skeleton
                latest_coverage = coverage
                is_covered = bool(coverage.get("is_covered", False))
                tool_result = {
                    "status": "ok" if is_covered else "needs_more_coverage",
                    "type": "finalized",
                    "notes": args.get("notes"),
                    "coverage": coverage,
                }
                messages.append(
                    {
                        "role": "tool",
                        "tool_call_id": tool_call_id,
                        "content": json.dumps(tool_result, ensure_ascii=False),
                    }
                )

                if is_covered:
                    finalized = True
                    log_success("[Planner] è¦†ç›–åº¦æ£€æŸ¥é€šè¿‡ï¼Œç»“æŸç»“æ„è§„åˆ’ã€‚")
                else:
                    coverage_retry += 1
                    log_info("ğŸ”§ è¦†ç›–åº¦æ£€æŸ¥æœªé€šè¿‡ï¼Œå°†ç»§ç»­ä½¿ç”¨è§„åˆ’å·¥å…·å®Œå–„ã€‚")
                    feedback_message = _build_coverage_feedback_message(
                        coverage=coverage, workflow=skeleton
                    )
                    messages.append({"role": "system", "content": feedback_message})
                    if coverage_retry > max_coverage_refine_rounds:
                        log_warn("å·²è¾¾åˆ°è¦†ç›–åº¦è¡¥å…¨ä¸Šé™ï¼Œä»æœ‰ç¼ºå¤±ç‚¹ï¼Œç»“æŸè§„åˆ’é˜¶æ®µã€‚")
                        finalized = True

                continue

            else:
                tool_result = {"status": "error", "message": f"æœªçŸ¥å·¥å…· {func_name}"}

            messages.append(
                {
                    "role": "tool",
                    "tool_call_id": tool_call_id,
                    "content": json.dumps(tool_result, ensure_ascii=False),
                }
            )

        if finalized:
            break

    if not finalized:
        if latest_coverage and not latest_coverage.get("is_covered", False):
            log_warn("[Planner] è§„åˆ’å›åˆç»“æŸä½†è¦†ç›–åº¦ä»æœªé€šè¿‡ï¼Œä½¿ç”¨å½“å‰éª¨æ¶ç»§ç»­åç»­é˜¶æ®µã€‚")
        else:
            log_warn("[Planner] æœªæ”¶åˆ° finalize_workflowï¼Œä½¿ç”¨å½“å‰éª¨æ¶ç»§ç»­åç»­é˜¶æ®µã€‚")

    if not finalized or not latest_skeleton:
        latest_skeleton = _prepare_skeleton_for_coverage(
            builder=builder, action_registry=action_registry, search_service=search_service
        )

    skeleton = _ensure_loop_exports_with_llm(
        workflow=latest_skeleton,
        action_registry=action_registry,
        nl_requirement=nl_requirement,
        model=OPENAI_MODEL,
    )

    return skeleton


__all__ = ["plan_workflow_structure_with_llm"]
