"""Planner utilities and workflow orchestration logic."""
import copy
import json
import os
from dataclasses import asdict
from collections import deque
from typing import Any, Dict, List, Mapping, Optional, Union

from openai import OpenAI

from velvetflow.action_registry import get_action_by_id
from velvetflow.config import OPENAI_MODEL
from velvetflow.models import PydanticValidationError, ValidationError, Workflow
from velvetflow.search import HybridActionSearchService

# ===================== 5. Planner å·¥å…·å®šä¹‰ =====================

PLANNER_TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "search_business_actions",
            "description": (
                "åœ¨æµ·é‡ä¸šåŠ¡åŠ¨ä½œåº“ä¸­æŒ‰è‡ªç„¶è¯­è¨€æŸ¥è¯¢å¯ç”¨åŠ¨ä½œã€‚è¿”å› candidates åˆ—è¡¨ï¼Œ"
                "åç»­ add_node(type='action') æ—¶ action_id å¿…é¡»å–è‡ªæœ€è¿‘ä¸€æ¬¡ candidates.idã€‚"
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {"type": "string"},
                    "top_k": {"type": "integer", "default": 5},
                },
                "required": ["query"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "set_workflow_meta",
            "description": "è®¾ç½®å·¥ä½œæµçš„åŸºæœ¬ä¿¡æ¯ï¼ˆåç§°ã€æè¿°ï¼‰ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "workflow_name": {"type": "string"},
                    "description": {"type": "string"},
                },
                "required": ["workflow_name"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "add_node",
            "description": (
                "åœ¨å·¥ä½œæµä¸­æ–°å¢ä¸€ä¸ªèŠ‚ç‚¹ã€‚\n"
                "- type='action'ï¼šè¯·å…ˆè°ƒç”¨ search_business_actions é€‰å‡ºåˆé€‚çš„ action_idã€‚\n"
                "  action_id å¿…é¡»æ˜¯æœ€è¿‘ä¸€æ¬¡ search_business_actions è¿”å›çš„ candidates.id ä¹‹ä¸€ã€‚\n"
                "- type='condition'ï¼šè¯·åœ¨ params ä¸­ä½¿ç”¨ç»“æ„åŒ–æ¡ä»¶ï¼Œä¾‹å¦‚ï¼š\n"
                "  {\"kind\": \"any_greater_than\", "
                "\"source\": \"result_of.some_node.items\", "
                "\"field\": \"value\", \"threshold\": 10 }\n"
                "æˆ– {\"kind\": \"equals\", "
                "\"source\": \"result_of.some_node.count\", \"value\": 0 }"
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "id": {"type": "string", "description": "èŠ‚ç‚¹å”¯ä¸€ ID"},
                    "type": {
                        "type": "string",
                        "enum": ["start", "end", "action", "condition", "loop", "parallel"],
                    },
                    "action_id": {
                        "type": "string",
                        "description": "type='action' æ—¶æŒ‡å®š action_idã€‚",
                        "nullable": True,
                    },
                    "display_name": {"type": "string"},
                    "params": {
                        "type": "object",
                        "description": "èŠ‚ç‚¹å‚æ•°ï¼Œå¯ä¸ºç©ºï¼Œä½†ç¨åä¼šåœ¨ç¬¬äºŒé˜¶æ®µè¡¥å…¨ã€‚",
                        "additionalProperties": True,
                    },
                },
                "required": ["id", "type"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "add_edge",
            "description": "æ–°å¢ä¸€æ¡æœ‰å‘è¾¹ï¼ˆfrom -> toï¼‰ï¼Œå¯é€‰ conditionï¼ˆtrue/false ç­‰ï¼‰ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "from_node": {"type": "string"},
                    "to_node": {"type": "string"},
                    "condition": {"type": "string", "nullable": True},
                },
                "required": ["from_node", "to_node"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "finalize_workflow",
            "description": "å½“ä½ è®¤ä¸ºç»“æ„å·²ç»è¦†ç›–éœ€æ±‚æ—¶è°ƒç”¨ï¼Œç»“æŸè§„åˆ’é˜¶æ®µã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "ready": {"type": "boolean", "default": True},
                    "notes": {"type": "string"},
                },
                "required": ["ready"],
            },
        },
    },
]


# ===================== 6. WorkflowBuilder =====================

class WorkflowBuilder:
    def __init__(self):
        self.workflow_name: str = "unnamed_workflow"
        self.description: str = ""
        self.nodes: Dict[str, Dict[str, Any]] = {}
        self.edges: List[Dict[str, Any]] = []

    def set_meta(self, name: str, description: Optional[str]):
        if name:
            self.workflow_name = name
        if description:
            self.description = description or ""

    def add_node(self, node_id: str, node_type: str,
                 action_id: Optional[str],
                 display_name: Optional[str],
                 params: Optional[Dict[str, Any]]):
        if node_id in self.nodes:
            print(f"[Builder] èŠ‚ç‚¹ {node_id} å·²å­˜åœ¨ï¼Œå°†è¦†ç›–ã€‚")
        self.nodes[node_id] = {
            "id": node_id,
            "type": node_type,
            "action_id": action_id,
            "display_name": display_name,
            "params": params or {},
        }

    def add_edge(self, from_node: str, to_node: str, condition: Optional[str]):
        self.edges.append({"from": from_node, "to": to_node, "condition": condition})

    def to_workflow(self) -> Dict[str, Any]:
        return {
            "workflow_name": self.workflow_name,
            "description": self.description,
            "nodes": list(self.nodes.values()),
            "edges": self.edges,
        }


# ===================== 7. ä¿è¯ edges è¦†ç›–æ‰€æœ‰èŠ‚ç‚¹ =====================

def ensure_edges_connectivity(
    nodes: List[Dict[str, Any]],
    edges: List[Dict[str, Any]],
) -> List[Dict[str, Any]]:
    """
    ç›®æ ‡ï¼š
    - ä¿ç•™å·²æœ‰ edgeï¼ˆPlanner/LLM å·²ç»è®¾è®¡å¥½çš„ç»“æ„ï¼‰
    - ä¿è¯æ‰€æœ‰èŠ‚ç‚¹è‡³å°‘åœ¨ä¸€æ¡ edge ä¸­å‡ºç°ï¼ˆé™¤éåªæœ‰ä¸€ä¸ªèŠ‚ç‚¹ï¼‰
    - ä¿è¯ä»æŸä¸ª start èŠ‚ç‚¹èƒ½åˆ°æ‰€æœ‰èŠ‚ç‚¹ï¼ˆè¡¥å……å¿…è¦çš„è¾¹ï¼‰
    """

    if not nodes:
        return []

    node_ids = [n["id"] for n in nodes]
    id_set = set(node_ids)

    # 1) è¿‡æ»¤éæ³•è¾¹
    cleaned_edges: List[Dict[str, Any]] = []
    for e in edges:
        frm = e.get("from")
        to = e.get("to")
        if frm in id_set and to in id_set:
            cleaned_edges.append({"from": frm, "to": to, "condition": e.get("condition")})
    edges = cleaned_edges

    # 2) æ‰¾ start èŠ‚ç‚¹
    start_nodes = [n["id"] for n in nodes if n.get("type") == "start"]
    if not start_nodes:
        to_ids = {e["to"] for e in edges}
        start_nodes = [nid for nid in node_ids if nid not in to_ids]

    if not start_nodes:
        start_nodes = [node_ids[0]]

    # 3) BFS æ‰¾ reachable
    adj: Dict[str, List[str]] = {}
    for e in edges:
        adj.setdefault(e["from"], []).append(e["to"])

    reachable: set = set()
    dq = deque(start_nodes)
    while dq:
        x = dq.popleft()
        if x in reachable:
            continue
        reachable.add(x)
        for y in adj.get(x, []):
            if y not in reachable:
                dq.append(y)

    # 4) æŠŠä¸å¯è¾¾èŠ‚ç‚¹æŒ‚ä¸Šå»
    unreachable = [nid for nid in node_ids if nid not in reachable]
    if not unreachable:
        return edges  # å·²ç»å…¨è¿é€š

    from_ids = {e["from"] for e in edges}
    to_ids = {e["to"] for e in edges}
    tail_candidates = [nid for nid in node_ids if nid in from_ids and nid not in to_ids]
    if tail_candidates:
        current_tail = tail_candidates[0]
    else:
        current_tail = list(reachable)[-1] if reachable else start_nodes[0]

    for u in unreachable:
        if current_tail == u:
            continue
        edges.append({"from": current_tail, "to": u, "condition": None})
        current_tail = u

    return edges


# ===================== 8. Action æ ¡éªŒä¸çº å =====================

def ensure_registered_actions(
    workflow: Union[Workflow, Dict[str, Any]],
    action_registry: List[Dict[str, Any]],
    search_service: Optional[HybridActionSearchService] = None,
) -> Union[Workflow, Dict[str, Any]]:
    """
    ç¡®ä¿æ‰€æœ‰ action èŠ‚ç‚¹å¼•ç”¨çš„ action_id éƒ½å­˜åœ¨äºæ³¨å†Œè¡¨ã€‚

    - å¦‚æœ action_id åˆæ³•ï¼Œä¿æŒä¸å˜ï¼›
    - å¦‚æœ action_id ç¼ºå¤±æˆ–æœªæ³¨å†Œï¼Œå°è¯•ç”¨èŠ‚ç‚¹ display_name è¿›è¡Œæœç´¢æ›¿æ¢ï¼›
    - å¦‚æœä¾ç„¶æ— æ³•åŒ¹é…ï¼Œåˆ™æ¸…ç©º action_idï¼Œé¿å…æºå¸¦éæ³• ID è¿›å…¥åç»­é˜¶æ®µã€‚
    """

    actions_by_id = _index_actions_by_id(action_registry)
    original_type = Workflow if isinstance(workflow, Workflow) else dict
    workflow_dict = (
        workflow.model_dump(by_alias=True)
        if isinstance(workflow, Workflow)
        else copy.deepcopy(workflow)
    )

    nodes = workflow_dict.get("nodes", []) if isinstance(workflow_dict, dict) else []

    for node in nodes:
        if node.get("type") != "action":
            continue

        aid = node.get("action_id")
        if aid and aid in actions_by_id:
            continue

        nid = node.get("id", "<unknown>")
        display_name = node.get("display_name") or ""

        replacement: Optional[str] = None
        if search_service and display_name:
            candidates = search_service.search(query=display_name, top_k=1)
            if candidates:
                replacement = candidates[0].get("action_id")

        if replacement:
            print(
                f"[ActionGuard] èŠ‚ç‚¹ '{nid}' çš„ action_id='{aid}' æœªæ³¨å†Œï¼Œ"
                f"å·²æ ¹æ® display_name='{display_name}' æ›¿æ¢ä¸º '{replacement}'ã€‚"
            )
            node["action_id"] = replacement
        else:
            if aid:
                print(
                    f"[ActionGuard] èŠ‚ç‚¹ '{nid}' çš„ action_id='{aid}' æœªæ³¨å†Œä¸”æ— æ³•è‡ªåŠ¨æ›¿æ¢ï¼Œ"
                    "å·²æ¸…ç©ºè¯¥å­—æ®µä»¥ä¾¿åç»­æµç¨‹é‡æ–°è¡¥é½ã€‚"
                )
            node["action_id"] = None

    if original_type is Workflow:
        return Workflow.model_validate(workflow_dict)
    return workflow_dict


# ===================== 9. edges ä¸ºç©ºæ—¶ç”¨ LLM æ¥çº¿ =====================

def synthesize_edges_with_llm(
    nodes: List[Dict[str, Any]],
    nl_requirement: str,
    model: str = OPENAI_MODEL,
) -> List[Dict[str, Any]]:
    """
    å½“ç¬¬ä¸€é˜¶æ®µæ²¡æœ‰ç”Ÿæˆä»»ä½• edges æ—¶ï¼Œè®© LLM æ ¹æ®èŠ‚ç‚¹åˆ—è¡¨å’Œéœ€æ±‚è¡¥ä¸€ä»½ edgesã€‚
    """
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

    node_brief = [
        {
            "id": n["id"],
            "type": n.get("type"),
            "action_id": n.get("action_id"),
            "display_name": n.get("display_name"),
        }
        for n in nodes
    ]

    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªå·¥ä½œæµæ¥çº¿åŠ©æ‰‹ã€‚\n"
        "ç°åœ¨æœ‰ä¸€ç»„å·²ç»ç¡®å®šçš„èŠ‚ç‚¹ nodesï¼ˆæ¯ä¸ªèŠ‚ç‚¹æœ‰ id/type/action_id/display_nameï¼‰ï¼Œ\n"
        "ä½†æ˜¯ edges ä¸ºç©ºã€‚\n"
        "ä½ çš„ä»»åŠ¡æ˜¯ï¼š\n"
        "1. æ ¹æ®ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€éœ€æ±‚å’Œè¿™äº›èŠ‚ç‚¹çš„å«ä¹‰ï¼Œæ¨ç†å®ƒä»¬çš„æ‰§è¡Œé¡ºåºå’Œåˆ†æ”¯ç»“æ„ã€‚\n"
        "2. ç”Ÿæˆä¸€ç»„ edgesï¼Œæ¯æ¡ edge å½¢å¦‚ï¼š\n"
        "   {\"from\": \"èŠ‚ç‚¹ID\", \"to\": \"èŠ‚ç‚¹ID\", \"condition\": \"true/false æˆ– null\"}\n"
        "3. æ•´ä½“å¿…é¡»æ˜¯ä¸€ä¸ªæœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰ï¼Œé€šå¸¸ä» type='start' èŠ‚ç‚¹å¼€å§‹ï¼Œåˆ° type='end' èŠ‚ç‚¹ç»“æŸã€‚\n"
        "4. å¦‚æœå­˜åœ¨æ¡ä»¶èŠ‚ç‚¹(type='condition')ï¼Œè¯·ç”¨ edge.condition è¡¨ç¤º true/false åˆ†æ”¯ï¼Œ\n"
        "   æ— æ¡ä»¶é¡ºåºæ‰§è¡Œæ—¶ condition ç”¨ nullã€‚\n"
        "5. è¿”å›çš„ JSON å¿…é¡»æ˜¯ï¼š{\"edges\": [ ... ]}ï¼Œä¸è¦åŒ…å«å…¶å®ƒå­—æ®µï¼Œä¹Ÿä¸è¦åŠ ä»£ç å—æ ‡è®°ã€‚"
    )

    user_payload = {
        "nl_requirement": nl_requirement,
        "nodes": node_brief,
    }

    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": json.dumps(user_payload, ensure_ascii=False)},
        ],
        temperature=0.2,
    )

    content = resp.choices[0].message.content or ""
    text = content.strip()
    if text.startswith("```"):
        text = text.strip("`")
        if "\n" in text:
            first_line, rest = text.split("\n", 1)
            if first_line.strip().lower().startswith("json"):
                text = rest

    try:
        obj = json.loads(text)
        edges = obj.get("edges", [])
        if not isinstance(edges, list):
            raise ValueError("edges ä¸æ˜¯ list")
        for e in edges:
            if "from" not in e or "to" not in e:
                raise ValueError("edge ç¼ºå°‘ from/to")
        return edges
    except Exception as e:
        print("[synthesize_edges_with_llm] æ— æ³•è§£æ/ä½¿ç”¨ LLM è¿”å›çš„ edgesï¼Œé”™è¯¯ï¼š", e)
        print("åŸå§‹å†…å®¹ï¼š", content)
        return []


# ===================== 10. éœ€æ±‚è¦†ç›–æ ¡éªŒ + ç»“æ„æ”¹è¿› =====================

def check_requirement_coverage_with_llm(
    nl_requirement: str,
    workflow: Dict[str, Any],
    model: str = OPENAI_MODEL,
) -> Dict[str, Any]:
    """
    è®© LLM å®¡æ ¸ï¼šå½“å‰ workflow æ˜¯å¦å®Œå…¨è¦†ç›– nl_requirementã€‚
    è¿”å›ç»“æ„ç¤ºä¾‹ï¼š
    {
      "is_covered": true/false,
      "missing_points": ["...", "..."],
      "analysis": "..."
    }
    """
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„å·¥ä½œæµéœ€æ±‚è¦†ç›–åº¦å®¡æŸ¥å‘˜ã€‚\n"
        "ç»™å®šï¼š\n"
        "1) ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€éœ€æ±‚ nl_requirement\n"
        "2) å½“å‰çš„ workflowï¼ˆworkflow_name/description/nodes/edgesï¼‰\n\n"
        "ä½ çš„ä»»åŠ¡ï¼š\n"
        "1. å…ˆæŠŠ nl_requirement ä¸­çš„å…³é”®å­éœ€æ±‚æ‹†åˆ†æˆè‹¥å¹²ä¸ªâ€œåŸå­èƒ½åŠ›â€ï¼Œä¾‹å¦‚ï¼š\n"
        "   - æŸä¸ªè§¦å‘æ–¹å¼ï¼ˆå®šæ—¶ / äº‹ä»¶ / æ‰‹åŠ¨ç­‰ï¼‰\n"
        "   - è‹¥å¹²ä¸ªæ•°æ®è¯»å– / æŸ¥è¯¢æ­¥éª¤\n"
        "   - è‹¥å¹²ä¸ªè¿‡æ»¤ / æ¡ä»¶åˆ¤æ–­æ­¥éª¤\n"
        "   - è‹¥å¹²ä¸ªèšåˆ / ç»Ÿè®¡ / æ€»ç»“æ­¥éª¤\n"
        "   - è‹¥å¹²ä¸ªå¯¹å¤–åŠ¨ä½œï¼ˆé€šçŸ¥ã€å†™å…¥æ•°æ®åº“ã€è°ƒç”¨å¤–éƒ¨ç³»ç»Ÿç­‰ï¼‰\n"
        "   è¿™é‡Œçš„ä¾‹å­ä»…ç”¨äºè¯´æ˜â€œæ‹†åˆ†ç²’åº¦â€ï¼Œä¸è¦æŠŠå…·ä½“ä¸šåŠ¡è¯å¸¦å…¥å…¶å®ƒä»»åŠ¡ã€‚\n"
        "2. å†é€é¡¹æ£€æŸ¥å½“å‰ workflow æ˜¯å¦å¯¹è¿™äº›åŸå­èƒ½åŠ›éƒ½æœ‰å®Œæ•´çš„æ”¯æŒï¼š\n"
        "   - æ˜¯å¦æœ‰å¯¹åº”çš„èŠ‚ç‚¹ï¼›\n"
        "   - èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥é¡ºåºæ˜¯å¦åˆç†ï¼›\n"
        "   - æ˜¯å¦å­˜åœ¨æ˜æ˜¾ç¼ºå¤±ï¼ˆä¾‹å¦‚ï¼šéœ€æ±‚ä¸­æåˆ°â€œé€šçŸ¥â€ï¼Œä½† workflow ä¸­å®Œå…¨æ²¡æœ‰ä»»ä½•é€šçŸ¥/å†™å…¥ç›¸å…³èŠ‚ç‚¹ï¼‰ã€‚\n"
        "3. å¦‚æœå®Œå…¨è¦†ç›–ï¼Œåˆ™ is_covered=trueï¼Œmissing_points åˆ—è¡¨ä¸ºç©ºã€‚\n"
        "4. å¦‚æœæœ‰ä»»ä½•ä¸€æ¡éœ€æ±‚æ²¡æœ‰è¢«è¦†ç›–æˆ–åªè¢«éƒ¨åˆ†è¦†ç›–ï¼Œåˆ™ is_covered=falseï¼Œ\n"
        "   å¹¶åœ¨ missing_points ä¸­ç”¨ç®€çŸ­ä¸­æ–‡åˆ—å‡ºç¼ºå¤±ç‚¹ï¼ˆä¾‹å¦‚ï¼šâ€œç¼ºå°‘å¯¹ç‰¹å®šæ¡ä»¶çš„è¿‡æ»¤â€ã€â€œç¼ºå°‘ç»“æœæ±‡æ€»åå‘é€ç»™ç”¨æˆ·çš„æ­¥éª¤â€ç­‰ï¼‰ã€‚\n\n"
        "è¾“å‡ºæ ¼å¼ï¼ˆéå¸¸é‡è¦ï¼‰ï¼š\n"
        "è¿”å›ä¸€ä¸ª JSON å¯¹è±¡ï¼Œå½¢å¦‚ï¼š\n"
        "{\n"
        "  \"is_covered\": true/false,\n"
        "  \"missing_points\": [\"...\", \"...\"],\n"
        "  \"analysis\": \"è¯¦ç»†åˆ†æ\"\n"
        "}\n"
        "ä¸è¦æ·»åŠ é¢å¤–å­—æ®µï¼Œä¸è¦è¾“å‡ºä»£ç å—æ ‡è®°ã€‚"
    )

    payload = {
        "nl_requirement": nl_requirement,
        "workflow": workflow,
    }

    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": json.dumps(payload, ensure_ascii=False)},
        ],
        temperature=0.1,
    )

    content = resp.choices[0].message.content or ""
    text = content.strip()
    if text.startswith("```"):
        text = text.strip("`")
        if "\n" in text:
            first_line, rest = text.split("\n", 1)
            if first_line.strip().lower().startswith("json"):
                text = rest

    try:
        result = json.loads(text)
    except json.JSONDecodeError:
        print("[check_requirement_coverage_with_llm] æ— æ³•è§£æ JSONï¼ŒåŸå§‹å†…å®¹ï¼š")
        print(content)
        result = {
            "is_covered": False,
            "missing_points": ["LLM è¦†ç›–åº¦æ£€æŸ¥è§£æå¤±è´¥"],
            "analysis": content,
        }

    if "is_covered" not in result:
        result["is_covered"] = False
    if "missing_points" not in result or not isinstance(result["missing_points"], list):
        result["missing_points"] = []
    if "analysis" not in result:
        result["analysis"] = ""

    return result


def refine_workflow_structure_with_llm(
    nl_requirement: str,
    current_workflow: Dict[str, Any],
    missing_points: List[str],
    model: str = OPENAI_MODEL,
) -> Dict[str, Any]:
    """
    å½“å‘ç° workflow æœªå®Œå…¨è¦†ç›–éœ€æ±‚æ—¶ï¼Œè¯· LLM åœ¨ç°æœ‰ç»“æ„åŸºç¡€ä¸Šè¿›è¡Œæ”¹è¿›ï¼Œ
    è¡¥å……ç¼ºå¤±çš„èŠ‚ç‚¹/åˆ†æ”¯/æ¡ä»¶ç­‰ã€‚
    """
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªå·¥ä½œæµæ¶æ„å¸ˆï¼Œè´Ÿè´£åœ¨ç°æœ‰ workflow åŸºç¡€ä¸Šåšâ€œå¢é‡æ”¹è¿›â€ï¼Œ\n"
        "ä»¥ä¾¿å®Œå…¨æ»¡è¶³ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€éœ€æ±‚ã€‚\n\n"
        "å·²çŸ¥ï¼š\n"
        "1) nl_requirement æ˜¯ç”¨æˆ·çš„å®Œæ•´è‡ªç„¶è¯­è¨€éœ€æ±‚ï¼›\n"
        "2) current_workflow æ˜¯å½“å‰ workflowï¼ˆworkflow_name/description/nodes/edgesï¼‰ï¼Œ\n"
        "   å®ƒå·²ç»å®ç°äº†éƒ¨åˆ†éœ€æ±‚ï¼Œä½†è¿˜ä¸å®Œæ•´ï¼›\n"
        "3) missing_points æ˜¯å·²ç»è¯†åˆ«å‡ºçš„ç¼ºå¤±ç‚¹åˆ—è¡¨ï¼Œä¾‹å¦‚ï¼š\n"
        "   - \"ç¼ºå°‘å¯¹æŸä¸ªç‰¹å®šæ¡ä»¶çš„è¿‡æ»¤æ­¥éª¤\"\n"
        "   - \"ç¼ºå°‘å¯¹ç»“æœè¿›è¡Œæ±‡æ€»/ç»Ÿè®¡/æ€»ç»“çš„æ­¥éª¤\"\n"
        "   - \"ç¼ºå°‘å°†ç»“æœå‘é€ç»™æŒ‡å®šç”¨æˆ·æˆ–å†™å…¥å¤–éƒ¨ç³»ç»Ÿçš„æ­¥éª¤\"\n"
        "   è¿™äº›ç¤ºä¾‹åªæ˜¯ç¼ºå¤±ç±»å‹çš„æ¼”ç¤ºï¼Œä¸ä»£è¡¨å…·ä½“ä¸šåŠ¡ã€‚\n\n"
        "ä½ çš„ä»»åŠ¡ï¼š\n"
        "1. åœ¨ current_workflow çš„åŸºç¡€ä¸Šæ·»åŠ æˆ–è°ƒæ•´èŠ‚ç‚¹/edgesï¼Œä»¥è¡¥é½ missing_points æŒ‡å‡ºçš„èƒ½åŠ›ï¼›\n"
        "2. å°½é‡å¤ç”¨å·²æœ‰èŠ‚ç‚¹å’Œæ•°æ®æµï¼ˆresult_of.<node_id>ï¼‰ï¼Œé¿å…æ¨å€’é‡æ¥ï¼›\n"
        "3. åªåœ¨å¿…è¦æ—¶æ–°å¢èŠ‚ç‚¹ï¼ˆä¾‹å¦‚ï¼šä¸“é—¨ç”¨äºè¿‡æ»¤/èšåˆ/é€šçŸ¥çš„æ–°èŠ‚ç‚¹ï¼‰ï¼›\n"
        "4. ç¡®ä¿æ•´ä½“ä¾ç„¶æ˜¯ä¸€ä¸ªæœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰ï¼Œé€šå¸¸ä» start åˆ° endï¼›\n"
        "5. ä¸è¦åˆ é™¤å·²ç»æ­£ç¡®å®ç°éœ€æ±‚çš„éƒ¨åˆ†ï¼Œé™¤éå¿…é¡»é‡æ„ï¼›\n"
        "6. ä¸éœ€è¦è¡¥å…¨ params çš„æ‰€æœ‰ç»†èŠ‚ï¼ˆç¬¬äºŒé˜¶æ®µä¼šåšï¼‰ï¼Œä½†åº”æ˜¾å¼æ·»åŠ å¯¹åº”çš„èŠ‚ç‚¹å’Œ edgesã€‚\n\n"
        "è¾“å‡ºæ ¼å¼ï¼š\n"
        "è¿”å›ä¸€ä¸ªå®Œæ•´çš„ JSON å¯¹è±¡ï¼Œå½¢å¦‚ï¼š\n"
        "{\n"
        "  \"workflow_name\": \"...\",\n"
        "  \"description\": \"...\",\n"
        "  \"nodes\": [ ... ],\n"
        "  \"edges\": [ ... ]\n"
        "}\n"
        "ä¸è¦åŒ…å«å…¶ä»–é¡¶å±‚å­—æ®µï¼Œä¸è¦è¾“å‡ºä»£ç å—æ ‡è®°ã€‚"
    )

    payload = {
        "nl_requirement": nl_requirement,
        "current_workflow": current_workflow,
        "missing_points": missing_points,
    }

    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": json.dumps(payload, ensure_ascii=False)},
        ],
        temperature=0.2,
    )

    content = resp.choices[0].message.content or ""
    text = content.strip()
    if text.startswith("```"):
        text = text.strip("`")
        if "\n" in text:
            first_line, rest = text.split("\n", 1)
            if first_line.strip().lower().startswith("json"):
                text = rest

    try:
        refined = json.loads(text)
    except json.JSONDecodeError:
        print("[refine_workflow_structure_with_llm] æ— æ³•è§£æ JSONï¼ŒåŸå§‹å†…å®¹ï¼š")
        print(content)
        return current_workflow

    if not isinstance(refined, dict) or not isinstance(refined.get("nodes"), list) or not isinstance(refined.get("edges"), list):
        print("[refine_workflow_structure_with_llm] LLM è¿”å›çš„ç»“æ„ä¸å®Œæ•´ï¼Œå›é€€åˆ° current_workflowã€‚")
        return current_workflow

    return refined


# ===================== 11. ç¬¬ä¸€é˜¶æ®µï¼šç»“æ„è§„åˆ’ LLM =====================

def plan_workflow_structure_with_llm(
    nl_requirement: str,
    search_service: HybridActionSearchService,
    action_registry: List[Dict[str, Any]],
    max_rounds: int = 10,
    max_coverage_refine_rounds: int = 2,
) -> Dict[str, Any]:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
    builder = WorkflowBuilder()
    last_action_candidates: List[str] = []

    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªé€šç”¨ä¸šåŠ¡å·¥ä½œæµç¼–æ’åŠ©æ‰‹ã€‚\n"
        "ç³»ç»Ÿä¸­æœ‰ä¸€ä¸ª Action Registryï¼ŒåŒ…å«å¤§é‡ä¸šåŠ¡åŠ¨ä½œï¼Œä½ åªèƒ½é€šè¿‡ search_business_actions æŸ¥è¯¢ã€‚\n"
        "æ„å»ºæ–¹å¼ï¼š\n"
        "1) ä½¿ç”¨ set_workflow_meta è®¾ç½®å·¥ä½œæµåç§°å’Œæè¿°ã€‚\n"
        "2) å½“éœ€è¦ä¸šåŠ¡åŠ¨ä½œæ—¶ï¼Œå¿…é¡»å…ˆç”¨ search_business_actions æŸ¥è¯¢å€™é€‰ï¼›add_node(type='action') çš„ action_id å¿…é¡»å–è‡ªæœ€è¿‘ä¸€æ¬¡ candidates.idã€‚\n"
        "3) ä½¿ç”¨ add_edge è¿æ¥èŠ‚ç‚¹å½¢æˆæœ‰å‘å›¾ï¼ˆDAGï¼‰ï¼ŒåŒ…å«å¿…è¦çš„æ¡ä»¶/åˆ†æ”¯/å¾ªç¯/å¹¶è¡Œç­‰ã€‚\n"
        "4) å½“ç»“æ„å®Œæˆæ—¶è°ƒç”¨ finalize_workflowã€‚\n\n"
        "ã€éå¸¸é‡è¦çš„åŸåˆ™ã€‘\n"
        "1. æ‰€æœ‰ç¤ºä¾‹ï¼ˆåŒ…æ‹¬åç»­ä½ åœ¨è¡¥å‚é˜¶æ®µçœ‹åˆ°çš„ç¤ºä¾‹ï¼‰éƒ½åªæ˜¯ä¸ºè¯´æ˜â€œDSL çš„å†™æ³•â€å’Œâ€œèŠ‚ç‚¹ä¹‹é—´å¦‚ä½•è¿çº¿â€ï¼Œ\n"
        "   ä¸æ˜¯å®é™…çš„ä¸šåŠ¡çº¦æŸï¼Œä¸è¦åœ¨æ–°ä»»åŠ¡é‡Œç¡¬å¤ç”¨è¿™äº›ç¤ºä¾‹ä¸­çš„ä¸šåŠ¡åæˆ–å­—æ®µåã€‚\n"
        "2. ä½ å¿…é¡»ä¸¥æ ¼å›´ç»•å½“å‰å¯¹è¯ä¸­çš„è‡ªç„¶è¯­è¨€éœ€æ±‚æ¥è®¾è®¡ workflowï¼š\n"
        "   - è§¦å‘æ–¹å¼ï¼ˆå®šæ—¶ / äº‹ä»¶ / æ‰‹åŠ¨ï¼‰\n"
        "   - æ•°æ®æŸ¥è¯¢/è¯»å–\n"
        "   - ç­›é€‰/è¿‡æ»¤æ¡ä»¶\n"
        "   - èšåˆ/ç»Ÿè®¡/æ€»ç»“\n"
        "   - é€šçŸ¥ / å†™å…¥ / è½åº“ / è°ƒç”¨ä¸‹æ¸¸ç³»ç»Ÿ\n"
        "3. ä¸å…è®¸ä¸ºäº†æ¨¡ä»¿ç¤ºä¾‹ï¼Œè€Œåœ¨ä¸å½“å‰ä»»åŠ¡æ— å…³çš„æƒ…å†µä¸‹å¼•å…¥â€œå¥åº·/ä½“æ¸©/æ–°é—»/Nvidia/å‘˜å·¥/HRâ€ç­‰å…·ä½“è¯æ±‡ã€‚\n\n"
        "ã€è¦†ç›–åº¦è¦æ±‚ã€‘\n"
        "ä½ å¿…é¡»ç¡®ä¿å·¥ä½œæµç»“æ„èƒ½å¤Ÿå®Œå…¨è¦†ç›–ç”¨æˆ·è‡ªç„¶è¯­è¨€éœ€æ±‚ä¸­çš„æ¯ä¸ªå­ä»»åŠ¡ï¼Œè€Œä¸æ˜¯åªè¦†ç›–å‰åŠéƒ¨åˆ†ï¼š\n"
        "ä¾‹å¦‚ï¼Œå¦‚æœéœ€æ±‚åŒ…å«ï¼šè§¦å‘ + æŸ¥è¯¢ + ç­›é€‰ + æ€»ç»“ + é€šçŸ¥ï¼Œä½ ä¸èƒ½åªå®ç°è§¦å‘ + æŸ¥è¯¢ï¼Œ\n"
        "å¿…é¡»åœ¨ç»“æ„é‡Œæ˜¾å¼åŒ…å«ç­›é€‰ã€æ€»ç»“ã€é€šçŸ¥ç­‰å¯¹åº”èŠ‚ç‚¹å’Œæ•°æ®æµã€‚\n"
        "å½“ä½ ç¡®ä¿¡æ‰€æœ‰å­éœ€æ±‚éƒ½æœ‰å¯¹åº”çš„èŠ‚ç‚¹å’Œè¾¹æ—¶ï¼Œå†è°ƒç”¨ finalize_workflowã€‚"
    )

    messages: List[Dict[str, Any]] = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": nl_requirement},
    ]

    finalized = False

    # ---------- ç»“æ„è§„åˆ’ï¼ˆå¤šè½® tool-callingï¼‰ ----------
    for round_idx in range(max_rounds):
        print(f"\n===== ç»“æ„è§„åˆ’ Round {round_idx + 1} =====")
        resp = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=messages,
            tools=PLANNER_TOOLS,
            tool_choice="auto",
            temperature=0.2,
        )
        msg = resp.choices[0].message
        messages.append({
            "role": "assistant",
            "content": msg.content or "",
            "tool_calls": msg.tool_calls,
        })

        if not msg.tool_calls:
            print("[Planner] æœ¬è½®æ²¡æœ‰ tool_callsï¼Œæå‰ç»“æŸã€‚")
            break

        for tc in msg.tool_calls:
            func_name = tc.function.name
            raw_args = tc.function.arguments
            tool_call_id = tc.id
            try:
                args = json.loads(raw_args) if raw_args else {}
            except json.JSONDecodeError:
                print(f"[Error] è§£æå·¥å…·å‚æ•°å¤±è´¥: {raw_args}")
                args = {}

            print(f"[Planner] è°ƒç”¨å·¥å…·: {func_name}({args})")

            if func_name == "search_business_actions":
                query = args.get("query", "")
                top_k = int(args.get("top_k", 5))
                actions_raw = search_service.search(query=query, top_k=top_k)
                candidates = [
                    {
                        "id": a.get("action_id"),
                        "name": a.get("name", ""),
                        "description": a.get("description", ""),
                        "category": a.get("domain") or "general",
                    }
                    for a in actions_raw
                    if a.get("action_id")
                ]
                last_action_candidates = [c["id"] for c in candidates]
                tool_result = {
                    "status": "ok",
                    "query": query,
                    "actions": actions_raw,
                    "candidates": candidates,
                }

            elif func_name == "set_workflow_meta":
                builder.set_meta(args.get("workflow_name", ""), args.get("description"))
                tool_result = {"status": "ok", "type": "meta_set"}

            elif func_name == "add_node":
                node_type = args["type"]
                action_id = args.get("action_id")

                if node_type == "action":
                    if not last_action_candidates:
                        tool_result = {
                            "status": "error",
                            "message": "action èŠ‚ç‚¹å¿…é¡»åœ¨è°ƒç”¨ search_business_actions ä¹‹ååˆ›å»ºï¼Œè¯·å…ˆæŸ¥è¯¢å€™é€‰åŠ¨ä½œã€‚",
                        }
                    elif action_id not in last_action_candidates:
                        tool_result = {
                            "status": "error",
                            "message": "action_id å¿…é¡»æ˜¯æœ€è¿‘ä¸€æ¬¡ search_business_actions è¿”å›çš„ candidates.id ä¹‹ä¸€ã€‚",
                            "allowed_action_ids": last_action_candidates,
                        }
                    else:
                        builder.add_node(
                            node_id=args["id"],
                            node_type=node_type,
                            action_id=action_id,
                            display_name=args.get("display_name"),
                            params=args.get("params") or {},
                        )
                        tool_result = {"status": "ok", "type": "node_added", "node_id": args["id"]}
                else:
                    builder.add_node(
                        node_id=args["id"],
                        node_type=node_type,
                        action_id=action_id,
                        display_name=args.get("display_name"),
                        params=args.get("params") or {},
                    )
                    tool_result = {"status": "ok", "type": "node_added", "node_id": args["id"]}

            elif func_name == "add_edge":
                builder.add_edge(
                    from_node=args["from_node"],
                    to_node=args["to_node"],
                    condition=args.get("condition"),
                )
                tool_result = {"status": "ok", "type": "edge_added"}

            elif func_name == "finalize_workflow":
                finalized = True
                tool_result = {"status": "ok", "type": "finalized", "notes": args.get("notes")}

            else:
                tool_result = {"status": "error", "message": f"æœªçŸ¥å·¥å…· {func_name}"}

            messages.append({
                "role": "tool",
                "tool_call_id": tool_call_id,
                "content": json.dumps(tool_result, ensure_ascii=False),
            })

        if finalized:
            print("[Planner] æ”¶åˆ° finalize_workflowï¼Œç»“æŸç»“æ„è§„åˆ’ã€‚")
            break

    # ---------- æ¥çº¿ + è¿é€šæ€§è¡¥å…¨ ----------
    skeleton = builder.to_workflow()
    nodes = skeleton.get("nodes", [])
    edges = skeleton.get("edges", [])

    if not edges:
        print("\n[Planner] ç¬¬ä¸€é˜¶æ®µæ²¡æœ‰ç”Ÿæˆä»»ä½• edgesï¼Œè°ƒç”¨ LLM è¿›è¡Œè‡ªåŠ¨æ¥çº¿...")
        auto_edges = synthesize_edges_with_llm(nodes=nodes, nl_requirement=nl_requirement)
        if auto_edges:
            print(f"[Planner] LLM è‡ªåŠ¨ç”Ÿæˆäº† {len(auto_edges)} æ¡ edgesã€‚")
            skeleton["edges"] = auto_edges
        else:
            print("[Planner] LLM è‡ªåŠ¨æ¥çº¿å¤±è´¥ï¼Œä½¿ç”¨ä¿åº•çº¿æ€§ä¸²è”æ–¹å¼ç”Ÿæˆ edgesã€‚")
            start_nodes = [n for n in nodes if n.get("type") == "start"]
            end_nodes = [n for n in nodes if n.get("type") == "end"]
            middle_nodes = [n for n in nodes if n.get("type") not in ("start", "end")]

            ordered = start_nodes + middle_nodes + end_nodes
            auto_edges = []
            for i in range(len(ordered) - 1):
                auto_edges.append({
                    "from": ordered[i]["id"],
                    "to": ordered[i + 1]["id"],
                    "condition": None,
                })
            skeleton["edges"] = auto_edges

    skeleton["edges"] = ensure_edges_connectivity(nodes, skeleton["edges"])
    skeleton = ensure_registered_actions(
        skeleton, action_registry=action_registry, search_service=search_service
    )

    # ---------- è¦†ç›–åº¦æ ¡éªŒ + ç»“æ„æ”¹è¿› ----------
    for refine_round in range(max_coverage_refine_rounds + 1):
        print(f"\n==== è¦†ç›–åº¦æ ¡éªŒè½®æ¬¡ {refine_round} ====\n")
        coverage = check_requirement_coverage_with_llm(
            nl_requirement=nl_requirement,
            workflow=skeleton,
            model=OPENAI_MODEL,
        )
        print("è¦†ç›–åº¦æ£€æŸ¥ç»“æœï¼š", json.dumps(coverage, ensure_ascii=False, indent=2))

        if coverage.get("is_covered", False):
            print("âœ… å½“å‰ç»“æ„å·²ç»è¢«åˆ¤å®šä¸ºâ€œå®Œå…¨è¦†ç›–â€ç”¨æˆ·éœ€æ±‚ã€‚")
            break

        missing_points = coverage.get("missing_points", []) or []
        if not missing_points:
            print("âš ï¸ è¦†ç›–åº¦æ£€æŸ¥è®¤ä¸ºä¸å®Œæ•´ï¼Œä½† missing_points ä¸ºç©ºï¼Œä¸å†å°è¯•ç»“æ„æ”¹è¿›ã€‚")
            break

        if refine_round == max_coverage_refine_rounds:
            print("âš ï¸ å·²è¾¾åˆ°æœ€å¤§ç»“æ„æ”¹è¿›è½®æ¬¡ï¼Œä»è®¤ä¸ºä¸å®Œå…¨è¦†ç›–ï¼Œä¿ç•™å½“å‰ç»“æ„ç»§ç»­åç»­é˜¶æ®µã€‚")
            break

        print("ğŸ”§ æ£€æµ‹åˆ°æœªè¦†ç›–çš„éœ€æ±‚ç‚¹ï¼Œå°†è°ƒç”¨ LLM å¯¹å·¥ä½œæµç»“æ„è¿›è¡Œå¢é‡æ”¹è¿›ï¼š")
        for mp in missing_points:
            print(" -", mp)

        refined = refine_workflow_structure_with_llm(
            nl_requirement=nl_requirement,
            current_workflow=skeleton,
            missing_points=missing_points,
            model=OPENAI_MODEL,
        )

        refined_nodes = refined.get("nodes", [])
        refined_edges = refined.get("edges", [])
        refined["edges"] = ensure_edges_connectivity(refined_nodes, refined_edges)
        refined = ensure_registered_actions(
            refined, action_registry=action_registry, search_service=search_service
        )
        skeleton = refined

    return skeleton


# ===================== 12. ç¬¬äºŒé˜¶æ®µè¾…åŠ©ï¼šèŠ‚ç‚¹ä¸Šä¸‹æ¸¸å…³ç³» =====================

def build_node_relations(workflow_skeleton: Dict[str, Any]) -> Dict[str, Dict[str, List[str]]]:
    nodes = workflow_skeleton.get("nodes", [])
    edges = workflow_skeleton.get("edges", [])
    node_ids = {n["id"] for n in nodes}
    relations: Dict[str, Dict[str, List[str]]] = {
        nid: {"upstream": [], "downstream": []} for nid in node_ids
    }
    for e in edges:
        frm = e.get("from")
        to = e.get("to")
        if frm in node_ids and to in node_ids:
            relations[frm]["downstream"].append(to)
            relations[to]["upstream"].append(frm)
    return relations


# ===================== 13. ç¬¬äºŒé˜¶æ®µï¼šå‚æ•°è¡¥å…¨ LLM =====================

def fill_params_with_llm(
    workflow_skeleton: Dict[str, Any],
    action_registry: List[Dict[str, Any]],
    model: str = OPENAI_MODEL,
) -> Dict[str, Any]:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

    action_schemas = {}
    for a in action_registry:
        aid = a["action_id"]
        action_schemas[aid] = {
            "name": a.get("name", ""),
            "description": a.get("description", ""),
            "domain": a.get("domain", ""),
            "arg_schema": a.get("arg_schema"),
            "output_schema": a.get("output_schema"),
        }

    node_relations = build_node_relations(workflow_skeleton)

    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªå·¥ä½œæµå‚æ•°è¡¥å…¨åŠ©æ‰‹ã€‚\n"
        "å·²æœ‰ä¸€ä¸ªå·¥ä½œæµ skeletonï¼šèŠ‚ç‚¹(id/type/action_id/display_name)å’Œ edges å·²ç¡®å®šï¼Œ"
        "ä½†å¾ˆå¤šèŠ‚ç‚¹çš„ params ä¸ºç©ºæˆ–ä¸å®Œæ•´ã€‚\n"
        "å¦æœ‰ action_schemasï¼ˆaction_id -> arg_schema/output_schemaï¼‰å’Œ node_relationsï¼ˆæ¯ä¸ªèŠ‚ç‚¹çš„ä¸Šä¸‹æ¸¸å…³ç³»ï¼‰ã€‚\n\n"
        "ã€é‡è¦è¯´æ˜ï¼šç¤ºä¾‹ä»…ä¸ºæ¨¡å¼ï¼Œä¸ä»£è¡¨å…·ä½“ä¸šåŠ¡ã€‘\n"
        "ä¸‹é¢æ‰€æœ‰ç¤ºä¾‹ï¼ˆåŒ…æ‹¬åˆ—è¡¨å­—æ®µåã€æ ¼å¼æ¨¡æ¿ä¸­çš„æ–‡å­—ç­‰ï¼‰ä»…ç”¨äºè¯´æ˜ DSL çš„ä½¿ç”¨æ–¹å¼ï¼Œ\n"
        "å®é™…ä»»åŠ¡ä¸­å¿…é¡»æ ¹æ®å½“å‰ action çš„ output_schema å’Œä¸šåŠ¡è¯­ä¹‰æ¥é€‰å–å­—æ®µåã€èŠ‚ç‚¹åå’Œå­—ç¬¦ä¸²å†…å®¹ï¼Œ\n"
        "ä¸è¦åœ¨ä¸å½“å‰ä»»åŠ¡æ— å…³çš„åœºæ™¯ä¸­ç¡¬å¥—â€œå‘˜å·¥/ä½“æ¸©/æ–°é—»/Nvidiaâ€ç­‰å…·ä½“è¯æ±‡ã€‚\n\n"
        "ã€ä»»åŠ¡ã€‘\n"
        "1. å¯¹ type='action' ä¸”æœ‰ action_id çš„èŠ‚ç‚¹ï¼Œæ ¹æ®å¯¹åº” arg_schema å¡«å…… paramsï¼Œ\n"
        "   è¦†ç›–æ‰€æœ‰ required å­—æ®µï¼Œå¹¶ç»™å‡ºåˆç†çš„å ä½å€¼ï¼ˆå¯ä»¥æ˜¯ç¤ºä¾‹å€¼ï¼Œä½†è¦è¯­ä¹‰åˆç†ï¼‰ã€‚\n"
        "2. å½“æŸä¸ªå­—æ®µçš„å€¼éœ€è¦æ¥è‡ªä¸Šæ¸¸èŠ‚ç‚¹è¾“å‡ºæ—¶ï¼Œè¯·ä½¿ç”¨â€œæ•°æ®ç»‘å®š DSLâ€ï¼š\n"
        "   2.1 æœ€ç®€å•ï¼šä»ä¸Šæ¸¸ç›´æ¥å–å€¼æˆ–è®¡æ•°ï¼Œä¾‹å¦‚ï¼š\n"
        "       - ç›´æ¥å¼•ç”¨ï¼š\n"
        "         {\"__from__\": \"result_of.some_node.items\", \"__agg__\": \"identity\"}\n"
        "       - æŒ‰æ¡ä»¶è®¡æ•°ï¼š\n"
        "         {\n"
        "           \"__from__\": \"result_of.some_node.items\",\n"
        "           \"__agg__\": \"count_if\",\n"
        "           \"field\": \"value\",  // è¿™é‡Œçš„ value åªæ˜¯ç¤ºæ„å­—æ®µå\n"
        "           \"op\": \">\",\n"
        "           \"value\": 10\n"
        "         }\n"
        "   2.2 å¯¹äºâ€œå…ˆè¿‡æ»¤å†æ ¼å¼åŒ–æˆæ¶ˆæ¯æ–‡æœ¬â€çš„æƒ…å†µï¼Œæ¨èä½¿ç”¨ **pipeline èšåˆ DSL**ï¼š\n"
        "       ç¤ºä¾‹ï¼ˆåªè¯´æ˜ç»“æ„ï¼Œä¸ä»£è¡¨å…·ä½“ä¸šåŠ¡å«ä¹‰ï¼‰ï¼š\n"
        "       {\n"
        "         \"__from__\": \"result_of.list_node.items\",\n"
        "         \"__agg__\": \"pipeline\",\n"
        "         \"steps\": [\n"
        "           {\"op\": \"filter\", \"field\": \"score\", \"cmp\": \">\", \"value\": 0.8},\n"
        "           {\"op\": \"map\", \"field\": \"id\"},\n"
        "           {\"op\": \"format_join\", \"format\": \"ID={value} å¼‚å¸¸\", \"sep\": \"\\n\"}\n"
        "         ]\n"
        "       }\n"
        "       - filter æ­¥éª¤ï¼šä¿ç•™æ»¡è¶³æ¡ä»¶çš„å…ƒç´ ï¼ˆcmp æ”¯æŒ >,>=,<,<=,==ï¼‰ã€‚\n"
        "       - map æ­¥éª¤ï¼šä»æ¯ä¸ªå…ƒç´ ä¸­å–æŸä¸ªå­—æ®µç»„æˆæ–°çš„åˆ—è¡¨ã€‚\n"
        "       - format_join æ­¥éª¤ï¼šå¯¹åˆ—è¡¨ä¸­æ¯ä¸ªå…ƒç´ ç”¨ format ä¸­çš„ {value} æ›¿æ¢ï¼Œç„¶åç”¨ sep æ‹¼æ¥æˆä¸€ä¸ªå­—ç¬¦ä¸²ã€‚\n"
        "   2.3 ä¸ºå…¼å®¹å·²æœ‰å†™æ³•ï¼Œä¹Ÿå…è®¸ä½¿ç”¨ç®€åŒ–çš„ filter_mapï¼ˆæ‰§è¡Œå™¨ä¼šè‡ªåŠ¨ç¿»è¯‘æˆ pipelineï¼‰ï¼š\n"
        "       {\n"
        "         \"__from__\": \"result_of.list_node.items\",\n"
        "         \"__agg__\": \"filter_map\",\n"
        "         \"filter_field\": \"score\",\n"
        "         \"filter_op\": \">\",\n"
        "         \"filter_value\": 0.8,\n"
        "         \"map_field\": \"id\",\n"
        "         \"format\": \"ID={value} å¼‚å¸¸\"\n"
        "       }\n\n"
        "3. å¯¹ type='condition' çš„èŠ‚ç‚¹ï¼Œæ ¹æ® display_nameã€ä¸Šä¸‹æ¸¸å…³ç³»å’Œæ•´ä½“è¯­ä¹‰ï¼Œ\n"
        "   ä½¿ç”¨ç»“æ„åŒ–æ¡ä»¶ paramsï¼Œä¾‹å¦‚ï¼ˆåªæ˜¯æ¨¡å¼ç¤ºä¾‹ï¼‰ï¼š\n"
        "   {\"kind\": \"any_greater_than\", "
        "\"source\": \"result_of.some_node.items\", "
        "\"field\": \"score\", \"threshold\": 0.8 }\n"
        "   æˆ– {\"kind\": \"equals\", "
        "\"source\": \"result_of.other_node.count\", \"value\": 0 }ã€‚\n"
        "   è¿™é‡Œçš„ some_node / items / score / count éƒ½æ˜¯ç¤ºèŒƒæ€§çš„å ä½åï¼Œ\n"
        "   å®é™…éœ€è¦æ ¹æ®è¯¥èŠ‚ç‚¹é€‰æ‹©çš„ action çš„ output_schema æ¥å†³å®šã€‚\n\n"
        "4. start/end èŠ‚ç‚¹å…è®¸ params ä¸ºç©º {}ã€‚\n"
        "5. è¿”å›çš„ JSON ç»“æ„å¿…é¡»ä¸è¾“å…¥ workflow_skeleton ç›¸åŒï¼Œåªæ˜¯èŠ‚ç‚¹çš„ params æ›´å®Œæ•´ã€‚\n"
        "6. åªè¿”å› JSON å¯¹è±¡æœ¬èº«ï¼Œä¸è¦åŠ ä»£ç å—æ ‡è®°ã€‚"
    )

    user_payload = {
        "workflow_skeleton": workflow_skeleton,
        "node_relations": node_relations,
        "action_schemas": action_schemas,
    }

    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": json.dumps(user_payload, ensure_ascii=False)},
        ],
        temperature=0.1,
    )

    content = resp.choices[0].message.content or ""
    text = content.strip()
    if text.startswith("```"):
        text = text.strip("`")
        if "\n" in text:
            first_line, rest = text.split("\n", 1)
            if first_line.strip().lower().startswith("json"):
                text = rest

    try:
        completed_workflow = json.loads(text)
    except json.JSONDecodeError:
        print("[fill_params_with_llm] æ— æ³•è§£ææ¨¡å‹è¿”å› JSONï¼ŒåŸå§‹å†…å®¹ï¼š")
        print(content)
        raise

    return completed_workflow


# ===================== 14. é™æ€æ ¡éªŒå·¥å…·å‡½æ•° =====================

def _index_actions_by_id(action_registry: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:
    return {a["action_id"]: a for a in action_registry}


def _index_nodes_by_id(workflow: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
    return {n["id"]: n for n in workflow.get("nodes", [])}


def _check_output_path_against_schema(
    source_path: str,
    nodes_by_id: Dict[str, Dict[str, Any]],
    actions_by_id: Dict[str, Dict[str, Any]],
) -> Optional[str]:
    """
    å¯¹è¯¸å¦‚ "result_of.fetch_temperatures.data" æˆ– "result_of.node_id.foo.bar" åšé™æ€æ ¡éªŒï¼š
    - result_of.<node_id> å¿…é¡»å­˜åœ¨
    - è¯¥ node å¿…é¡»æœ‰ action_id
    - å¯¹åº” action çš„ output_schema å¿…é¡»åŒ…å«ç¬¬ä¸€å±‚å­—æ®µï¼ˆdata / fooï¼‰

    è¿”å›:
      - None: æ ¡éªŒé€šè¿‡
      - str: å…·ä½“é”™è¯¯ä¿¡æ¯
    """
    if not isinstance(source_path, str):
        return f"source/__from__ åº”è¯¥æ˜¯å­—ç¬¦ä¸²ï¼Œä½†æ”¶åˆ°ç±»å‹: {type(source_path)}"

    parts = source_path.split(".")
    if len(parts) < 2 or parts[0] != "result_of":
        return None

    node_id = parts[1]
    rest_path = parts[2:]

    if node_id not in nodes_by_id:
        return f"è·¯å¾„ '{source_path}' å¼•ç”¨çš„èŠ‚ç‚¹ '{node_id}' ä¸å­˜åœ¨ã€‚"

    node = nodes_by_id[node_id]
    action_id = node.get("action_id")
    if not action_id:
        return f"è·¯å¾„ '{source_path}' å¼•ç”¨çš„èŠ‚ç‚¹ '{node_id}' æ²¡æœ‰ action_idï¼Œæ— æ³•ä» output_schema æ ¡éªŒã€‚"

    action_def = actions_by_id.get(action_id)
    if not action_def:
        return f"è·¯å¾„ '{source_path}' å¼•ç”¨çš„èŠ‚ç‚¹ '{node_id}' çš„ action_id='{action_id}' ä¸åœ¨ Action Registry ä¸­ã€‚"

    output_schema = action_def.get("output_schema")
    if not isinstance(output_schema, dict):
        return f"action_id='{action_id}' æ²¡æœ‰å®šä¹‰ output_schemaï¼Œæ— æ³•æ ¡éªŒè·¯å¾„ '{source_path}'ã€‚"

    if not rest_path:
        return None

    err = _schema_path_error(output_schema, rest_path)
    if err:
        return f"è·¯å¾„ '{source_path}' æ— æ•ˆï¼š{err}"

    return None


def _schema_path_error(schema: Mapping[str, Any], fields: List[str]) -> Optional[str]:
    """Check whether a dotted field path exists in a JSON schema."""

    if not isinstance(schema, Mapping):
        return "output_schema ä¸æ˜¯å¯¹è±¡ï¼Œæ— æ³•æ ¡éªŒå­—æ®µè·¯å¾„ã€‚"

    current: Mapping[str, Any] = schema
    idx = 0
    while idx < len(fields):
        name = fields[idx]
        typ = current.get("type")

        if typ == "array":
            current = current.get("items") or {}
            continue

        if typ == "object":
            props = current.get("properties") or {}
            if name not in props:
                return f"å­—æ®µ '{name}' ä¸å­˜åœ¨ï¼Œå·²çŸ¥å­—æ®µæœ‰: {list(props.keys())}"
            current = props[name]
            idx += 1
            continue

        return f"å­—æ®µè·¯å¾„ '{'.'.join(fields)}' ä¸ schema ç±»å‹ '{typ}' ä¸åŒ¹é…ï¼ˆæœŸæœ› object/arrayï¼‰ã€‚"

    return None


def _get_array_item_schema_from_output(
    source_path: str,
    nodes_by_id: Dict[str, Dict[str, Any]],
    actions_by_id: Dict[str, Dict[str, Any]],
) -> Optional[Dict[str, Any]]:
    """
    ç»™ä¸€ä¸ª source/__from__ è·¯å¾„ï¼ˆä¾‹å¦‚ "result_of.fetch_temperatures.data"ï¼‰ï¼Œ
    å¦‚æœå®ƒæŒ‡å‘çš„æ˜¯æŸä¸ª action çš„ output_schema ä¸­çš„æ•°ç»„å­—æ®µï¼ˆä¾‹å¦‚ data: array[...]ï¼‰ï¼Œ
    å°±è¿”å›è¿™ä¸ªæ•°ç»„çš„ item schemaï¼ˆå³ itemsï¼‰ï¼Œå¦åˆ™è¿”å› Noneã€‚
    """
    if not isinstance(source_path, str):
        return None

    parts = source_path.split(".")
    if len(parts) < 3 or parts[0] != "result_of":
        return None

    src_node_id = parts[1]
    first_field = parts[2]

    node = nodes_by_id.get(src_node_id)
    if not node:
        return None

    action_id = node.get("action_id")
    if not action_id:
        return None

    action_def = actions_by_id.get(action_id)
    if not action_def:
        return None

    output_schema = action_def.get("output_schema")
    if not isinstance(output_schema, dict):
        return None

    props = output_schema.get("properties") or {}
    field_schema = props.get(first_field)
    if not isinstance(field_schema, dict):
        return None

    if field_schema.get("type") == "array" and isinstance(field_schema.get("items"), dict):
        return field_schema["items"]

    return None


def _check_array_item_field(
    source_path: str,
    field_name: str,
    nodes_by_id: Dict[str, Dict[str, Any]],
    actions_by_id: Dict[str, Dict[str, Any]],
) -> Optional[str]:
    """
    æ£€æŸ¥ "result_of.xxx.data" è¿™ç§è·¯å¾„æŒ‡å‘çš„æ•°ç»„å…ƒç´  schema é‡Œï¼Œ
    æ˜¯å¦å­˜åœ¨ field_name è¿™ä¸ªå­—æ®µã€‚
    - è¿”å› None è¡¨ç¤ºæ²¡é—®é¢˜ï¼ˆæˆ–æ— æ³•åˆ¤æ–­ï¼‰
    - è¿”å› str è¡¨ç¤ºç¡®å®šå­˜åœ¨é—®é¢˜ï¼Œè¿™ä¸ª str å°±æ˜¯é”™è¯¯ä¿¡æ¯
    """
    if not field_name:
        return None

    item_schema = _get_array_item_schema_from_output(source_path, nodes_by_id, actions_by_id)
    if not item_schema:
        return None

    props = item_schema.get("properties") or {}
    if field_name not in props:
        return (
            f"source è·¯å¾„ '{source_path}' æŒ‡å‘çš„æ•°ç»„å…ƒç´  schema ä¸­ä¸å­˜åœ¨å­—æ®µ '{field_name}'ï¼Œ"
            f"å·²çŸ¥çš„å­—æ®µæœ‰: {list(props.keys())}"
        )
    return None


# ===================== 15. åç«¯æ ¡éªŒ =====================

def validate_completed_workflow(
    workflow: Dict[str, Any],
    action_registry: List[Dict[str, Any]],
) -> List[ValidationError]:
    errors: List[ValidationError] = []

    nodes = workflow.get("nodes", [])
    edges = workflow.get("edges", [])

    nodes_by_id = _index_nodes_by_id(workflow)
    node_ids = set(nodes_by_id.keys())
    actions_by_id = _index_actions_by_id(action_registry)

    # ---------- edges æ ¡éªŒ ----------
    for e in edges:
        frm = e.get("from")
        to = e.get("to")
        if frm not in node_ids:
            errors.append(
                ValidationError(
                    code="INVALID_EDGE",
                    node_id=frm,
                    field="from",
                    message=f"Edge from '{frm}' -> '{to}' ä¸­ï¼Œfrom èŠ‚ç‚¹ä¸å­˜åœ¨ã€‚",
                )
            )
        if to not in node_ids:
            errors.append(
                ValidationError(
                    code="INVALID_EDGE",
                    node_id=to,
                    field="to",
                    message=f"Edge from '{frm}' -> '{to}' ä¸­ï¼Œto èŠ‚ç‚¹ä¸å­˜åœ¨ã€‚",
                )
            )

    # ---------- å›¾è¿é€šæ€§æ ¡éªŒ ----------
    start_nodes = [n["id"] for n in nodes if n.get("type") == "start"]
    reachable: set = set()
    if nodes and start_nodes:
        adj: Dict[str, List[str]] = {}
        for e in edges:
            frm = e.get("from")
            to = e.get("to")
            if frm in node_ids and to in node_ids:
                adj.setdefault(frm, []).append(to)

        dq = deque(start_nodes)
        while dq:
            nid = dq.popleft()
            if nid in reachable:
                continue
            reachable.add(nid)
            for nxt in adj.get(nid, []):
                if nxt not in reachable:
                    dq.append(nxt)

        for nid in node_ids - reachable:
            errors.append(
                ValidationError(
                    code="DISCONNECTED_GRAPH",
                    node_id=nid,
                    field=None,
                    message=f"èŠ‚ç‚¹ '{nid}' æ— æ³•ä» start èŠ‚ç‚¹åˆ°è¾¾ã€‚",
                )
            )

    # ---------- èŠ‚ç‚¹æ ¡éªŒ ----------
    for n in nodes:
        nid = n["id"]
        ntype = n.get("type")
        action_id = n.get("action_id")
        params = n.get("params", {})

        # 1) action èŠ‚ç‚¹
        if ntype == "action" and action_id:
            action_def = actions_by_id.get(action_id)
            if not action_def:
                errors.append(
                    ValidationError(
                        code="UNKNOWN_ACTION_ID",
                        node_id=nid,
                        field="action_id",
                        message=f"èŠ‚ç‚¹ '{nid}' çš„ action_id '{action_id}' ä¸åœ¨ Action Registry ä¸­ã€‚",
                    )
                )
            else:
                schema = action_def.get("arg_schema") or {}
                required_fields = (schema.get("required") or []) if isinstance(schema, dict) else []

                if not isinstance(params, dict) or len(params) == 0:
                    if required_fields:
                        for field in required_fields:
                            errors.append(
                                ValidationError(
                                    code="MISSING_REQUIRED_PARAM",
                                    node_id=nid,
                                    field=field,
                                    message=(
                                        f"action èŠ‚ç‚¹ '{nid}' çš„ params ä¸ºç©ºï¼Œä½† action '{action_id}' æœ‰å¿…å¡«å­—æ®µ '{field}'ã€‚"
                                    ),
                                )
                            )
                else:
                    for field in required_fields:
                        if field not in params:
                            errors.append(
                                ValidationError(
                                    code="MISSING_REQUIRED_PARAM",
                                    node_id=nid,
                                    field=field,
                                    message=(
                                        f"action èŠ‚ç‚¹ '{nid}' çš„ params ç¼ºå°‘å¿…å¡«å­—æ®µ '{field}' (action_id='{action_id}')"
                                    ),
                                )
                            )

            # ç»‘å®š DSL é™æ€æ ¡éªŒ
            def _walk_params_for_from(obj: Any, path_prefix: str = ""):
                if isinstance(obj, dict):
                    if "__from__" in obj:
                        source_path = obj["__from__"]
                        err = _check_output_path_against_schema(
                            source_path=source_path,
                            nodes_by_id=nodes_by_id,
                            actions_by_id=actions_by_id,
                        )
                        if err:
                            errors.append(
                                ValidationError(
                                    code="SCHEMA_MISMATCH",
                                    node_id=nid,
                                    field=path_prefix or "params",
                                    message=(
                                        f"action èŠ‚ç‚¹ '{nid}' çš„å‚æ•°ç»‘å®šï¼ˆ{path_prefix or '<root>'}ï¼‰æ— æ•ˆï¼š{err}"
                                    ),
                                )
                            )

                        agg = obj.get("__agg__")

                        if agg == "count_if":
                            fld = obj.get("field")
                            if isinstance(fld, str):
                                item_err = _check_array_item_field(
                                    source_path, fld, nodes_by_id, actions_by_id
                                )
                                if item_err:
                                    errors.append(
                                        ValidationError(
                                            code="SCHEMA_MISMATCH",
                                            node_id=nid,
                                            field=f"{path_prefix or 'params'}.field",
                                            message=(
                                                f"action èŠ‚ç‚¹ '{nid}' çš„å‚æ•°ç»‘å®šï¼ˆ{path_prefix or '<root>'}ï¼‰ä¸­ count_if.field='{fld}' æ— æ•ˆï¼š{item_err}"
                                            ),
                                        )
                                    )

                        if agg == "filter_map":
                            for fld_key in ("filter_field", "map_field"):
                                fld = obj.get(fld_key)
                                if isinstance(fld, str):
                                    item_err = _check_array_item_field(
                                        source_path, fld, nodes_by_id, actions_by_id
                                    )
                                    if item_err:
                                        errors.append(
                                            ValidationError(
                                                code="SCHEMA_MISMATCH",
                                                node_id=nid,
                                                field=f"{path_prefix or 'params'}.{fld_key}",
                                                message=(
                                                    f"action èŠ‚ç‚¹ '{nid}' çš„å‚æ•°ç»‘å®šï¼ˆ{path_prefix or '<root>'}ï¼‰ä¸­ {agg}.{fld_key}='{fld}' æ— æ•ˆï¼š{item_err}"
                                                ),
                                            )
                                        )

                        if agg == "pipeline":
                            steps = obj.get("steps") or []
                            for idx, step in enumerate(steps):
                                if not isinstance(step, dict):
                                    continue
                                fld = step.get("field")
                                if isinstance(fld, str):
                                    item_err = _check_array_item_field(
                                        source_path, fld, nodes_by_id, actions_by_id
                                    )
                                    if item_err:
                                        errors.append(
                                            ValidationError(
                                                code="SCHEMA_MISMATCH",
                                                node_id=nid,
                                                field=f"{path_prefix or 'params'}.pipeline.steps[{idx}].field",
                                                message=(
                                                    f"action èŠ‚ç‚¹ '{nid}' çš„å‚æ•°ç»‘å®šï¼ˆ{path_prefix or '<root>'}ï¼‰ä¸­ pipeline.steps[{idx}].field='{fld}' æ— æ•ˆï¼š{item_err}"
                                                ),
                                            )
                                        )

                    for k, v in obj.items():
                        new_prefix = f"{path_prefix}.{k}" if path_prefix else k
                        _walk_params_for_from(v, new_prefix)
                elif isinstance(obj, list):
                    for idx, v in enumerate(obj):
                        new_prefix = f"{path_prefix}[{idx}]"
                        _walk_params_for_from(v, new_prefix)

            _walk_params_for_from(params)

        # 2) condition èŠ‚ç‚¹
        if ntype == "condition":
            if not isinstance(params, dict) or len(params) == 0:
                errors.append(
                    ValidationError(
                        code="MISSING_REQUIRED_PARAM",
                        node_id=nid,
                        field="params",
                        message=f"condition èŠ‚ç‚¹ '{nid}' çš„ params ä¸ºç©ºï¼Œè‡³å°‘éœ€è¦ kind/source ç­‰å­—æ®µã€‚",
                    )
                )
            else:
                kind = params.get("kind")
                if not kind:
                    errors.append(
                        ValidationError(
                            code="MISSING_REQUIRED_PARAM",
                            node_id=nid,
                            field="kind",
                            message=f"condition èŠ‚ç‚¹ '{nid}' ç¼ºå°‘ kind å­—æ®µã€‚",
                        )
                    )
                else:
                    if kind == "any_greater_than":
                        for field in ["source", "field", "threshold"]:
                            if field not in params:
                                errors.append(
                                    ValidationError(
                                        code="MISSING_REQUIRED_PARAM",
                                        node_id=nid,
                                        field=field,
                                        message=(
                                            f"condition èŠ‚ç‚¹ '{nid}' (kind=any_greater_than) ç¼ºå°‘å­—æ®µ '{field}'ã€‚"
                                        ),
                                    )
                                )
                        src = params.get("source")
                        fld = params.get("field")
                        if isinstance(src, str) and isinstance(fld, str):
                            item_err = _check_array_item_field(src, fld, nodes_by_id, actions_by_id)
                            if item_err:
                                errors.append(
                                    ValidationError(
                                        code="SCHEMA_MISMATCH",
                                        node_id=nid,
                                        field="field",
                                        message=f"condition èŠ‚ç‚¹ '{nid}' çš„ field='{fld}' æ— æ•ˆï¼š{item_err}",
                                    )
                                )

                    elif kind == "equals":
                        for field in ["source", "value"]:
                            if field not in params:
                                errors.append(
                                    ValidationError(
                                        code="MISSING_REQUIRED_PARAM",
                                        node_id=nid,
                                        field=field,
                                        message=(
                                            f"condition èŠ‚ç‚¹ '{nid}' (kind=equals) ç¼ºå°‘å­—æ®µ '{field}'ã€‚"
                                        ),
                                    )
                                )

                source = params.get("source")
                if isinstance(source, str):
                    if source.startswith("result_of."):
                        try:
                            rest = source[len("result_of."):]
                            node_part = rest.split(".", 1)[0]
                            if node_part not in node_ids:
                                errors.append(
                                    ValidationError(
                                        code="INVALID_EDGE",
                                        node_id=nid,
                                        field="source",
                                        message=(
                                            f"condition èŠ‚ç‚¹ '{nid}' çš„ source='{source}' å¼•ç”¨äº†ä¸å­˜åœ¨çš„èŠ‚ç‚¹ ID '{node_part}'ã€‚"
                                        ),
                                    )
                                )
                        except Exception:
                            errors.append(
                                ValidationError(
                                    code="SCHEMA_MISMATCH",
                                    node_id=nid,
                                    field="source",
                                    message=(
                                        f"condition èŠ‚ç‚¹ '{nid}' çš„ source='{source}' æ ¼å¼å¼‚å¸¸ã€‚"
                                    ),
                                )
                            )

                    schema_err = _check_output_path_against_schema(
                        source_path=source,
                        nodes_by_id=nodes_by_id,
                        actions_by_id=actions_by_id,
                    )
                    if schema_err:
                        errors.append(
                            ValidationError(
                                code="SCHEMA_MISMATCH",
                                node_id=nid,
                                field="source",
                                message=(
                                    f"condition èŠ‚ç‚¹ '{nid}' çš„ source='{source}' ä¸ä¸Šæ¸¸ output_schema ä¸åŒ¹é…ï¼š{schema_err}"
                                ),
                            )
                        )

    return errors


# ===================== 16. è‡ªä¿®å¤ LLM =====================

def repair_workflow_with_llm(
    broken_workflow: Dict[str, Any],
    validation_errors: List[ValidationError],
    action_registry: List[Dict[str, Any]],
    model: str = OPENAI_MODEL,
) -> Dict[str, Any]:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

    action_schemas = {}
    for a in action_registry:
        aid = a["action_id"]
        action_schemas[aid] = {
            "name": a.get("name", ""),
            "description": a.get("description", ""),
            "domain": a.get("domain", ""),
            "arg_schema": a.get("arg_schema"),
            "output_schema": a.get("output_schema"),
        }

    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªå·¥ä½œæµä¿®å¤åŠ©æ‰‹ã€‚\n"
        "å½“å‰æœ‰ä¸€ä¸ª workflow JSON å’Œä¸€ç»„ç»“æ„åŒ–æ ¡éªŒé”™è¯¯ validation_errorsã€‚\n"
        "validation_errors æ˜¯ JSON æ•°ç»„ï¼Œå…ƒç´ åŒ…å« code/node_id/field/messageã€‚\n"
        "è¿™äº›é”™è¯¯æ¥è‡ªï¼š\n"
        "- action å‚æ•°ç¼ºå¤±æˆ–ä¸ç¬¦åˆ arg_schema\n"
        "- condition æ¡ä»¶ä¸å®Œæ•´\n"
        "- source/__from__ è·¯å¾„å¼•ç”¨äº†ä¸å­˜åœ¨çš„èŠ‚ç‚¹\n"
        "- source/__from__ è·¯å¾„ä¸ä¸Šæ¸¸ action çš„ output_schema ä¸åŒ¹é…\n"
        "- source/__from__ æŒ‡å‘çš„æ•°ç»„å…ƒç´  schema ä¸­ä¸å­˜åœ¨æŸä¸ªå­—æ®µ\n\n"
        "æ€»ä½“ç›®æ ‡ï¼šåœ¨â€œå°½é‡ä¸æ”¹å˜å·¥ä½œæµæ•´ä½“ç»“æ„â€çš„å‰æä¸‹ï¼Œä¿®å¤è¿™äº›é”™è¯¯ï¼Œä½¿ workflow é€šè¿‡é™æ€æ ¡éªŒã€‚\n\n"
        "å…·ä½“è¦æ±‚ï¼ˆå¾ˆé‡è¦ï¼Œè¯·ä¸¥æ ¼éµå®ˆï¼‰ï¼š\n"
        "1. ç»“æ„ä¿æŒç¨³å®šï¼š\n"
        "   - ä¸è¦å¢åŠ æˆ–åˆ é™¤èŠ‚ç‚¹ï¼›\n"
        "   - ä¸è¦éšæ„å¢åŠ æˆ–åˆ é™¤ edgesï¼›\n"
        "   - åªèƒ½åœ¨å¿…è¦æ—¶å±€éƒ¨è°ƒæ•´ edge.conditionï¼ˆtrue/false/nullï¼‰ï¼Œä¸€èˆ¬æƒ…å†µä¸‹ä¿æŒ edges åŸæ ·ã€‚\n\n"
        "2. action èŠ‚ç‚¹ä¿®å¤ä¼˜å…ˆçº§ï¼š\n"
        "   - é¦–å…ˆæ ¹æ® action_schemas[action_id].arg_schema è¡¥é½ params é‡Œç¼ºå¤±çš„å¿…å¡«å­—æ®µï¼Œæˆ–ä¿®æ­£é”™è¯¯ç±»å‹ï¼›\n"
        "   - å¦‚æœ action_id æœ¬èº«æ˜¯åˆæ³•çš„ï¼ˆå­˜åœ¨äº action_schemas ä¸­ï¼‰ï¼Œä¼˜å…ˆâ€œä¿® paramsâ€ï¼Œä¸è¦æ”¹ action_idï¼›\n"
        "   - åªæœ‰å½“ validation_errors æ˜ç¡®æŒ‡å‡º action_id ä¸å­˜åœ¨æ—¶ï¼Œæ‰è€ƒè™‘æŠŠ action_id æ”¹æˆä¸€ä¸ªæ›´åˆç†çš„å€™é€‰ï¼Œ"
        "     å¹¶åŒæ­¥æ›´æ–°è¯¥èŠ‚ç‚¹çš„ params ä½¿ä¹‹ç¬¦åˆæ–°çš„ arg_schemaã€‚\n\n"
        "3. å…³äº source/__from__ ä¸ output_schema çš„é”™è¯¯ï¼š\n"
        "   - å½“ validation_errors æç¤ºâ€œè·¯å¾„ä¸ä¸Šæ¸¸ output_schema ä¸åŒ¹é…â€æ—¶ï¼Œ"
        "     ä¼˜å…ˆä¿®æ”¹è·¯å¾„æœ¬èº«ï¼ˆsource æˆ– __from__ çš„å­—ç¬¦ä¸²ï¼‰ï¼Œè€Œä¸è¦æ”¹ action_id æˆ–åˆ é™¤èŠ‚ç‚¹ï¼›\n"
        "   - ä¿®æ”¹è·¯å¾„æ—¶çš„ç­–ç•¥ï¼š\n"
        "       a) node_id éƒ¨åˆ†åº”æŒ‡å‘ä¸€ä¸ªå­˜åœ¨ä¸”æœ‰ action_id çš„èŠ‚ç‚¹ï¼›\n"
        "       b) å­—æ®µéƒ¨åˆ†åº”ä¸è¯¥ action çš„ output_schema.properties ä¸­çš„å­—æ®µå¯¹é½ï¼›\n"
        "       c) è‹¥åªæ˜¯å­—æ®µæ‹¼å†™é”™è¯¯ï¼Œå°½é‡åªæ”¹å­—æ®µåï¼›\n"
        "       d) è‹¥å¼•ç”¨äº†é”™è¯¯çš„èŠ‚ç‚¹ï¼Œåˆ™ä¼˜å…ˆæ”¹ä¸ºçœŸæ­£äº§ç”Ÿè¯¥æ•°æ®çš„ä¸Šæ¸¸ action èŠ‚ç‚¹ã€‚\n\n"
        "4. æ•°ç»„å…ƒç´ å­—æ®µç›¸å…³é”™è¯¯ï¼š\n"
        "   - å½“é”™è¯¯ä¿¡æ¯ä¸­åŒ…å«â€œæ•°ç»„å…ƒç´  schema ä¸­ä¸å­˜åœ¨å­—æ®µâ€ä¹‹ç±»æè¿°æ—¶ï¼Œ\n"
        "     è¯·ä¼˜å…ˆä¿®æ­£è¿™äº›å­—æ®µåæœ¬èº«ï¼Œè€Œä¸æ˜¯ä¿®æ”¹ action_id æˆ–åˆ é™¤èŠ‚ç‚¹ã€‚\n"
        "   - å­—æ®µååº”ä»è¯¥æ•°ç»„å…ƒç´  schema çš„ properties ä¸­é€‰æ‹©æœ€åˆç†çš„å€™é€‰ã€‚\n\n"
        "5. condition èŠ‚ç‚¹ä¿®å¤ï¼š\n"
        "   - ç»§ç»­ä½¿ç”¨ç»“æ„åŒ– paramsï¼Œä¾‹å¦‚ any_greater_than / equalsï¼›\n"
        "   - è¡¥é½ kind/source/field/threshold/value ç­‰å¿…éœ€å­—æ®µï¼›\n"
        "   - source å¿…é¡»å¼•ç”¨ä¸€ä¸ªçœŸå®å­˜åœ¨çš„èŠ‚ç‚¹ï¼Œä¸”è·¯å¾„å‰ç¼€ result_of.<node_id> ä¸è¯¥èŠ‚ç‚¹çš„ output_schema ä¸€è‡´ã€‚\n\n"
        "6. å‚æ•°ç»‘å®š DSL ä¿®å¤ï¼ˆ__from__ åŠå…¶èšåˆé€»è¾‘ï¼‰ï¼š\n"
        "   - å¯¹äº {\"__from__\": \"result_of.xxx.data\", \"__agg__\": \"...\", ...}ï¼š\n"
        "       - æ£€æŸ¥ __from__ è·¯å¾„æ˜¯å¦åˆæ³•ã€ä¸ output_schema å¯¹é½ï¼›\n"
        "       - æ£€æŸ¥ count_if/filter_map/pipeline ä¸­çš„ field/filter_field/map_field æ˜¯å¦å­˜åœ¨äºæ•°ç»„å…ƒç´  schema ä¸­ï¼›\n"
        "   - å½“é”™è¯¯æ¶‰åŠè¿™äº›å­—æ®µæ—¶ï¼Œä¼˜å…ˆåªæ”¹å­—æ®µåï¼ˆæ ¹æ®å…ƒç´  schema çš„ propertiesï¼‰ï¼Œä¿æŒèšåˆé€»è¾‘ä¸å˜ã€‚\n\n"
        "7. ä¿®æ”¹èŒƒå›´å°½é‡æœ€å°åŒ–ï¼š\n"
        "   - å½“æœ‰å¤šç§ä¿®å¤æ–¹å¼æ—¶ï¼Œä¼˜å…ˆé€‰æ‹©æ”¹åŠ¨æœ€å°ã€è¯­ä¹‰æœ€æ¥è¿‘åŸæ„çš„æ–¹æ¡ˆï¼ˆå¦‚åªæ”¹ä¸€ä¸ªå­—æ®µåï¼Œè€Œä¸æ˜¯é‡å†™æ•´ä¸ª paramsï¼‰ã€‚\n\n"
        "8. è¾“å‡ºè¦æ±‚ï¼š\n"
        "   - ä¿æŒé¡¶å±‚ç»“æ„ï¼šworkflow_name/description/nodes/edges ä¸å˜ï¼ˆä»…èŠ‚ç‚¹å†…éƒ¨å†…å®¹å¯è°ƒæ•´ï¼‰ï¼›\n"
        "   - èŠ‚ç‚¹çš„ id/type ä¸å˜ï¼›\n"
        "   - è¿”å›ä¿®å¤åçš„ workflow JSONï¼Œåªè¿”å› JSON å¯¹è±¡æœ¬èº«ï¼Œä¸è¦åŒ…å«ä»£ç å—æ ‡è®°ã€‚"
    )

    user_payload = {
        "workflow": broken_workflow,
        "validation_errors": [asdict(e) for e in validation_errors],
        "action_schemas": action_schemas,
    }

    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": json.dumps(user_payload, ensure_ascii=False)},
        ],
        temperature=0.1,
    )

    content = resp.choices[0].message.content or ""
    text = content.strip()
    if text.startswith("```"):
        text = text.strip("`")
        if "\n" in text:
            first_line, rest = text.split("\n", 1)
            if first_line.strip().lower().startswith("json"):
                text = rest

    try:
        repaired_workflow = json.loads(text)
    except json.JSONDecodeError:
        print("[repair_workflow_with_llm] æ— æ³•è§£ææ¨¡å‹è¿”å› JSONï¼ŒåŸå§‹å†…å®¹ï¼š")
        print(content)
        raise

    return repaired_workflow



# ===================== 17. æ€»æ§ï¼šä¸¤é˜¶æ®µ + è‡ªä¿®å¤ =====================

def plan_workflow_with_two_pass(
    nl_requirement: str,
    search_service: HybridActionSearchService,
    action_registry: List[Dict[str, Any]],
    max_rounds: int = 10,
    max_repair_rounds: int = 3,
) -> Workflow:
    skeleton_raw = plan_workflow_structure_with_llm(
        nl_requirement=nl_requirement,
        search_service=search_service,
        action_registry=action_registry,
        max_rounds=max_rounds,
        max_coverage_refine_rounds=2,
    )
    print("\n==== ç¬¬ä¸€é˜¶æ®µç»“æœï¼šWorkflow Skeleton ====\n")
    print(json.dumps(skeleton_raw, indent=2, ensure_ascii=False))

    skeleton = Workflow.model_validate(skeleton_raw)
    last_good_workflow: Workflow = skeleton

    completed_workflow_raw = fill_params_with_llm(
        workflow_skeleton=skeleton.model_dump(by_alias=True),
        action_registry=action_registry,
        model=OPENAI_MODEL,
    )

    try:
        completed_workflow = Workflow.model_validate(completed_workflow_raw)
        completed_workflow = ensure_registered_actions(
            completed_workflow,
            action_registry=action_registry,
            search_service=search_service,
        )
        if isinstance(completed_workflow, Workflow):
            current_workflow = completed_workflow
        else:
            current_workflow = Workflow.model_validate(completed_workflow)
        last_good_workflow = current_workflow
    except PydanticValidationError as e:
        print(
            "\n[plan_workflow_with_two_pass] è­¦å‘Šï¼šfill_params_with_llm è¿”å›çš„ç»“æ„æ— æ³•é€šè¿‡æ ¡éªŒï¼Œ", e
        )
        current_workflow = last_good_workflow

    for repair_round in range(max_repair_rounds + 1):
        print(f"\n==== æ ¡éªŒ + è‡ªä¿®å¤è½®æ¬¡ {repair_round} ====\n")
        print("å½“å‰ workflowï¼š")
        print(json.dumps(current_workflow.model_dump(by_alias=True), indent=2, ensure_ascii=False))

        errors = validate_completed_workflow(
            current_workflow.model_dump(by_alias=True),
            action_registry=action_registry,
        )

        if not errors:
            print("\n==== æ ¡éªŒé€šè¿‡ï¼Œæ— éœ€è¿›ä¸€æ­¥ä¿®å¤ ====\n")
            last_good_workflow = current_workflow
            return current_workflow

        print("\n==== æ ¡éªŒæœªé€šè¿‡ï¼Œé”™è¯¯åˆ—è¡¨ ====")
        for e in errors:
            print(
                " -",
                f"[code={e.code}] node={e.node_id} field={e.field} message={e.message}",
            )

        if repair_round == max_repair_rounds:
            print("\n==== å·²åˆ°æœ€å¤§ä¿®å¤è½®æ¬¡ï¼Œä»æœ‰é”™è¯¯ï¼Œè¿”å›æœ€åä¸€ä¸ªåˆæ³•ç»“æ„ç‰ˆæœ¬ ====\n")
            return last_good_workflow

        print(f"\n==== è°ƒç”¨ LLM è¿›è¡Œç¬¬ {repair_round + 1} æ¬¡ä¿®å¤ ====\n")
        repaired_raw = repair_workflow_with_llm(
            broken_workflow=current_workflow.model_dump(by_alias=True),
            validation_errors=errors,
            action_registry=action_registry,
            model=OPENAI_MODEL,
        )

        try:
            repaired_workflow = Workflow.model_validate(repaired_raw)
            repaired_workflow = ensure_registered_actions(
                repaired_workflow,
                action_registry=action_registry,
                search_service=search_service,
            )
            if isinstance(repaired_workflow, Workflow):
                current_workflow = repaired_workflow
            else:
                current_workflow = Workflow.model_validate(repaired_workflow)
            last_good_workflow = current_workflow
        except PydanticValidationError:
            print(
                "[plan_workflow_with_two_pass] è­¦å‘Šï¼šrepair_workflow_with_llm è¿”å›çš„ç»“æ„ä¸åŒ…å«åˆæ³•çš„ nodes/edgesï¼Œæœ¬è½®ä¿®å¤ç»“æœè¢«å¿½ç•¥ã€‚"
            )

    return last_good_workflow


